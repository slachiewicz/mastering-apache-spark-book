== [[JsonFileFormat]] JsonFileFormat -- Built-In Support for Files in JSON Format

[[shortName]]
`JsonFileFormat` is a `TextBasedFileFormat` for *json* format (i.e. link:spark-sql-DataSourceRegister.adoc#shortName[registers itself to handle files in json format]).

[source, scala]
----
spark.read.format("json").load("json-datasets")

// or the same as above using a shortcut
spark.read.json("json-datasets")
----

[[options]]
[[JSONOptions]]
.JsonFileFormat's Options
[cols="1,1,2",options="header",width="100%"]
|===
| Option
| Default Value
| Description

| [[multiLine]] `multiLine`
| `false`
| Controls whether...FIXME

| [[mode]] `mode`
|
|
|===

=== [[isSplitable]] `isSplitable` Method

[source, scala]
----
isSplitable(
  sparkSession: SparkSession,
  options: Map[String, String],
  path: Path): Boolean
----

NOTE: `isSplitable` is a part of link:LINK#isSplitable[FileFormat Contract].

`isSplitable`...FIXME

=== [[inferSchema]] `inferSchema` Method

[source, scala]
----
inferSchema(
  sparkSession: SparkSession,
  options: Map[String, String],
  files: Seq[FileStatus]): Option[StructType]
----

NOTE: `inferSchema` is a part of link:LINK#inferSchema[FileFormat Contract].

`inferSchema`...FIXME

=== [[prepareWrite]] `prepareWrite` Method

[source, scala]
----
prepareWrite(
  sparkSession: SparkSession,
  job: Job,
  options: Map[String, String],
  dataSchema: StructType): OutputWriterFactory
----

NOTE: `prepareWrite` is a part of link:LINK#prepareWrite[FileFormat Contract].

`prepareWrite`...FIXME

=== [[buildReader]] `buildReader` Method

[source, scala]
----
buildReader(
  sparkSession: SparkSession,
  dataSchema: StructType,
  partitionSchema: StructType,
  requiredSchema: StructType,
  filters: Seq[Filter],
  options: Map[String, String],
  hadoopConf: Configuration): PartitionedFile => Iterator[InternalRow]
----

NOTE: `buildReader` is a part of link:LINK#buildReader[FileFormat Contract].

`buildReader`...FIXME
