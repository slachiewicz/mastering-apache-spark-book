== [[Expand]] Expand Unary Logical Operator

`Expand` is a link:spark-sql-LogicalPlan.adoc#UnaryNode[unary logical operator] that represents `Cube`, `Rollup`, link:spark-sql-LogicalPlan-GroupingSets.adoc[GroupingSets] and link:spark-sql-Expression-TimeWindow.adoc[TimeWindow] logical operators after they have been resolved at <<analyzer, analysis phase>>.

```
FIXME Examples for
1. Cube
2. Rollup
3. GroupingSets
4. See TimeWindow

val q = ...

scala> println(q.queryExecution.logical.numberedTreeString)
...
```

NOTE: `Expand` logical operator is resolved to `ExpandExec` physical operator in link:spark-sql-SparkStrategy-BasicOperators.adoc#Expand[BasicOperators] execution planning strategy.

[[properties]]
.Expand's Properties (in alphabetical order)
[width="100%",cols="1,2",options="header"]
|===
| Name
| Description

| `references`
| `AttributeSet` from <<projections, projections>>

| `validConstraints`
| Empty set of link:spark-sql-Expression.adoc[expressions]
|===

=== [[analyzer]] Analysis Phase

`Expand` logical operator is resolved to at link:spark-sql-Analyzer.adoc[analysis phase] in the following logical evaluation rules:

* link:spark-sql-Analyzer.adoc#ResolveGroupingAnalytics[ResolveGroupingAnalytics] (for `Cube`, `Rollup`, link:spark-sql-LogicalPlan-GroupingSets.adoc[GroupingSets] logical operators)
* link:spark-sql-Analyzer.adoc#TimeWindowing[TimeWindowing] (for link:spark-sql-Expression-TimeWindow.adoc[TimeWindow] logical operator)

NOTE: Aggregate -> (Cube|Rollup|GroupingSets) -> constructAggregate -> constructExpand

[source, scala]
----
val spark: SparkSession = ...
// using q from the example above
val plan = q.queryExecution.logical

scala> println(plan.numberedTreeString)
...FIXME
----

=== [[optimizer]] Rule-Based Logical Optimization Phase

* link:spark-sql-Optimizer-ColumnPruning.adoc[ColumnPruning]
* link:spark-sql-Optimizer.adoc#FoldablePropagation[FoldablePropagation]
* link:spark-sql-Optimizer.adoc#RewriteDistinctAggregates[RewriteDistinctAggregates]

=== [[computeStats]] `computeStats` Method

CAUTION: FIXME

NOTE: `computeStats` is a part of link:spark-sql-LogicalPlan.adoc#computeStats[LogicalPlan Contract] to calculating statistics estimates (for cost-based optimizer).

=== [[creating-instance]] Creating Expand Instance

`Expand` takes the following when created:

* [[projections]] Projection link:spark-sql-Expression.adoc[expressions]
* [[output]] Output schema link:spark-sql-Expression-Attribute.adoc[attributes]
* [[child]] Child link:spark-sql-LogicalPlan.adoc[logical plan]
