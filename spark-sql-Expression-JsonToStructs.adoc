== [[JsonToStructs]] JsonToStructs Unary Expression

`JsonToStructs` is a Catalyst link:spark-sql-Expression.adoc#UnaryExpression[unary] expression with link:spark-sql-Expression.adoc#TimeZoneAwareExpression[timezone] support and link:spark-sql-Expression.adoc#CodegenFallback[CodegenFallback].

`JsonToStructs` is <<creating-instance, created>> to represent link:spark-sql-functions.adoc#from_json[from_json] function.

[source, scala]
----
import org.apache.spark.sql.functions.from_json
val jsonCol = from_json($"json", new StructType())

import org.apache.spark.sql.catalyst.expressions.JsonToStructs
val jsonExpr = jsonCol.expr.asInstanceOf[JsonToStructs]
scala> println(jsonExpr.numberedTreeString)
00 jsontostructs('json, None)
01 +- 'json
----

`JsonToStructs` is link:spark-sql-Expression.adoc#ExpectsInputTypes[ExpectsInputTypes].

[[FAILFAST]]
[NOTE]
====
`JsonToStructs` uses <<parser, JacksonParser>> in `FAILFAST` mode that simply fails early when a corrupted/malformed record is found (and hence does not support `columnNameOfCorruptRecord` JSON option).
====

[[properties]]
.JsonToStructs's Properties
[width="100%",cols="1,2",options="header"]
|===
| Property
| Description

| [[converter]] `converter`
| Function that converts `Seq[InternalRow]` into...FIXME

| [[nullable]] `nullable`
| Enabled (i.e. `true`)

| [[parser]] `parser`
a| `JacksonParser` with <<rowSchema, rowSchema>> and link:spark-sql-JsonFileFormat.adoc#JSONOptions[JSON options]

NOTE: link:spark-sql-JsonFileFormat.adoc#JSONOptions[JSON options] are made up of the input <<options, options>> with link:spark-sql-JsonFileFormat.adoc#mode[mode] option as `FAILFAST` and the input <<timeZoneId, time zone>> as the default time zone.

| [[rowSchema]] `rowSchema`
a| link:spark-sql-StructType.adoc[StructType] that...FIXME

* <<schema, schema>> when of type `StructType`
* `StructType` of the elements in <<schema, schema>> when of type `ArrayType`
|===

=== [[creating-instance]] Creating JsonToStructs Instance

`JsonToStructs` takes the following when created:

* [[schema]] link:spark-sql-DataType.adoc[DataType]
* [[options]] Options
* [[child]] Child link:spark-sql-Expression.adoc[expression]
* [[timeZoneId]] Optional time zone ID

`JsonToStructs` initializes the <<internal-registries, internal registries and counters>>.

=== [[validateSchemaLiteral]] Parsing Table Schema for String Literals -- `validateSchemaLiteral` Method

[source, scala]
----
validateSchemaLiteral(exp: Expression): StructType
----

`validateSchemaLiteral` requests link:spark-sql-CatalystSqlParser.adoc[CatalystSqlParser] to link:spark-sql-AbstractSqlParser.adoc#parseTableSchema[parseTableSchema] for link:spark-sql-Expression-Literal.adoc[Literal] of link:spark-sql-DataType.adoc#StringType[StringType].

For any other non-``StringType`` link:spark-sql-DataType.adoc[types], `validateSchemaLiteral` reports a `AnalysisException`:

```
Expected a string literal instead of [expression]
```
