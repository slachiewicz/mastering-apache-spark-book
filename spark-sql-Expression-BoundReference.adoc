== [[BoundReference]] BoundReference Leaf Expression -- Reference to Value in Internal Binary Row

`BoundReference` is a link:spark-sql-Expression.adoc#LeafExpression[leaf expression] that is a reference to a value in link:spark-sql-InternalRow.adoc[internal binary row] at a specified <<ordinal, position>> and of specified <<dataType, data type>>.

`BoundReference` holds the following:

* [[ordinal]] Ordinal, i.e. the position
* [[dataType]] link:spark-sql-DataType.adoc[DataType]
* [[nullable]] Flag whether the value can be `nullable` or not

[source, scala]
----
import org.apache.spark.sql.catalyst.expressions.BoundReference
import org.apache.spark.sql.types.LongType
val boundRef = BoundReference(ordinal = 0, dataType = LongType, nullable = true)

scala> println(boundRef.toString)
input[0, bigint, true]

// create an InternalRow using ExpressionEncoder
import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder
import spark.implicits.newLongEncoder
val longExprEnc = newLongEncoder.asInstanceOf[ExpressionEncoder[Long]]
val row = longExprEnc.toRow(5)

val five = boundRef.eval(row).asInstanceOf[Long]
----

=== [[eval]] `eval` Method

[source, scala]
----
eval(input: InternalRow): Any
----

NOTE: `eval` is a part of link:spark-sql-Expression.adoc#eval[Expression Contract] that evaluates the expression to a JVM object for a given link:spark-sql-InternalRow.adoc[internal binary row].

`eval` gives the value at <<ordinal, position>> in the `input` link:spark-sql-InternalRow.adoc[internal binary row] that is of a correct type.

Internally, `eval` returns `null` if the value at the <<ordinal, position>> is `null`.

Otherwise, `eval` uses the methods of `InternalRow` per the defined <<dataType, data type>> to access the value.

.eval's DataType to InternalRow's Methods Mapping (in execution order)
[cols="1,1",options="header",width="100%"]
|===
| DataType
| InternalRow's Method

| BooleanType
| getBoolean

| ByteType | getByte
| ShortType | getShort
| IntegerType | getInt
| link:spark-sql-DataType.adoc#DateType[DateType] | getInt
| LongType | getLong
| TimestampType | getLong
| FloatType | getFloat
| DoubleType | getDouble
| StringType | getUTF8String
| BinaryType | getBinary
| CalendarIntervalType | getInterval
| DecimalType | getDecimal
| StructType | getStruct
| ArrayType | getArray
| MapType | getMap
| _others_ | get(ordinal, dataType)
|===

=== [[doGenCode]] Generating Java Source Code -- `doGenCode` Method

[source, scala]
----
doGenCode(ctx: CodegenContext, ev: ExprCode): ExprCode
----

NOTE: `doGenCode` is a part of link:spark-sql-Expression.adoc#doGenCode[Expression Contract].

`doGenCode`...FIXME
