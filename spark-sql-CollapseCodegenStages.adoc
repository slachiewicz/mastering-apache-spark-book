== [[CollapseCodegenStages]] CollapseCodegenStages Physical Preparation Rule -- Collapsing Physical Operators for Whole-Stage CodeGen

`CollapseCodegenStages` is a link:spark-sql-QueryExecution-SparkPlan-Preparations.adoc[physical preparation rule] that <<apply, collapses physical operators for Java code generation>> (as part of link:spark-sql-whole-stage-codegen.adoc[Java code generation]).

[NOTE]
====
You can disable `CollapseCodegenStages` (and so whole-stage codegen) by turning link:spark-sql-SQLConf.adoc#spark.sql.codegen.wholeStage[spark.sql.codegen.wholeStage] internal property off.

`spark.sql.codegen.wholeStage` property is enabled by default.

[source, scala]
----
import org.apache.spark.sql.internal.SQLConf.WHOLESTAGE_CODEGEN_ENABLED
scala> spark.conf.get(WHOLESTAGE_CODEGEN_ENABLED)
res0: String = true
----

Use link:spark-sql-SQLConf.adoc#wholeStageEnabled[SQLConf.wholeStageEnabled] method to access the current value.

[source, scala]
----
scala> spark.sessionState.conf.wholeStageEnabled
res1: Boolean = true
----
====

`CollapseCodegenStages` acts only on <<insertWholeStageCodegen, physical operators with CodegenSupport>> for which <<supportCodegen, Java code can really be generated>>.

[[conf]]
`CollapseCodegenStages` takes a link:spark-sql-SQLConf.adoc[SQLConf] when created.

TIP: Import `CollapseCodegenStages` and apply the rule directly to a physical plan to learn how the rule works.

[source, scala]
----
import org.apache.spark.sql.SparkSession
val spark: SparkSession = ...
val query = spark.range(2).join(spark.range(2), "id")

// the final result (after CollapseCodegenStages among other rules)
scala> query.explain
== Physical Plan ==
*Project [id#9L]
+- *BroadcastHashJoin [id#9L], [id#12L], Inner, BuildRight
   :- *Range (0, 2, step=1, splits=8)
   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, false]))
      +- *Range (0, 2, step=1, splits=8)

val plan = query.queryExecution.sparkPlan

// wholeStageEnabled is enabled
scala> println(spark.sessionState.conf.wholeStageEnabled)
true

import org.apache.spark.sql.execution.CollapseCodegenStages
val ccs = CollapseCodegenStages(conf = spark.sessionState.conf)

scala> ccs.ruleName
res0: String = org.apache.spark.sql.execution.CollapseCodegenStages

// Before CollapseCodegenStages
scala> println(plan.numberedTreeString)
00 Project [id#9L]
01 +- BroadcastHashJoin [id#9L], [id#12L], Inner, BuildRight
02    :- Range (0, 2, step=1, splits=8)
03    +- Range (0, 2, step=1, splits=8)

// After CollapseCodegenStages
// Note the star
val executedPlan = ccs.apply(plan)
scala> println(executedPlan.numberedTreeString)
00 *Project [id#9L]
01 +- *BroadcastHashJoin [id#9L], [id#12L], Inner, BuildRight
02    :- *Range (0, 2, step=1, splits=8)
03    +- *Range (0, 2, step=1, splits=8)

import org.apache.spark.sql.execution.WholeStageCodegenExec
val wsc = executedPlan(0).asInstanceOf[WholeStageCodegenExec]
scala> println(wsc.numberedTreeString)
00 *Project [id#9L]
01 +- *BroadcastHashJoin [id#9L], [id#12L], Inner, BuildRight
02    :- *Range (0, 2, step=1, splits=8)
03    +- *Range (0, 2, step=1, splits=8)

scala> println(wsc.child.numberedTreeString)
00 Project [id#9L]
01 +- BroadcastHashJoin [id#9L], [id#12L], Inner, BuildRight
02    :- Range (0, 2, step=1, splits=8)
03    +- Range (0, 2, step=1, splits=8)

// Let's disable wholeStage codegen
// CollapseCodegenStages becomes a noop

val newSpark = spark.newSession()
import org.apache.spark.sql.internal.SQLConf.WHOLESTAGE_CODEGEN_ENABLED
newSpark.sessionState.conf.setConf(WHOLESTAGE_CODEGEN_ENABLED, false)

scala> println(newSpark.sessionState.conf.wholeStageEnabled)
false

val ccsWholeStageDisabled = CollapseCodegenStages(conf = newSpark.sessionState.conf)
scala> println(ccsWholeStageDisabled.apply(plan).numberedTreeString)
00 Project [id#9L]
01 +- BroadcastHashJoin [id#9L], [id#12L], Inner, BuildRight
02    :- Range (0, 2, step=1, splits=8)
03    +- Range (0, 2, step=1, splits=8)
----

=== [[apply]] Inserting WholeStageCodegenExec to Physical Plan for Operators with CodeGen Support -- `apply` Method

[source, scala]
----
apply(plan: SparkPlan): SparkPlan
----

`apply` starts <<insertWholeStageCodegen, inserting WholeStageCodegenExec (with InputAdapter)>> in the input `plan` physical plan only when link:spark-sql-SQLConf.adoc#spark.sql.codegen.wholeStage[spark.sql.codegen.wholeStage] internal property is enabled. Otherwise, it does nothing at all (i.e. passes the input physical plan through unchanged).

[NOTE]
====
Input Adapters show themselves with no star in link:spark-sql-dataset-operators.adoc[explain].

[source, scala]
----
scala> spark.range(1).groupBy("id").count.explain
== Physical Plan ==
*HashAggregate(keys=[id#31L], functions=[count(1)])
+- Exchange hashpartitioning(id#31L, 200) // <-- no star here
   +- *HashAggregate(keys=[id#31L], functions=[partial_count(1)])
      +- *Range (0, 1, step=1, splits=8)
----
====

[NOTE]
====
link:spark-sql-SQLConf.adoc#spark.sql.codegen.wholeStage[spark.sql.codegen.wholeStage] property is enabled by default.

[source, scala]
----
import org.apache.spark.sql.internal.SQLConf.WHOLESTAGE_CODEGEN_ENABLED
scala> spark.conf.get(WHOLESTAGE_CODEGEN_ENABLED)
res0: String = true
----

Use link:spark-sql-SQLConf.adoc#wholeStageEnabled[SQLConf.wholeStageEnabled] method to access the current value.

[source, scala]
----
scala> spark.sessionState.conf.wholeStageEnabled
res1: Boolean = true
----
====

=== [[insertWholeStageCodegen]] Inserting WholeStageCodegenExec (with InputAdapter) for Physical Operators with Codegen Support -- `insertWholeStageCodegen` Internal Method

[source, scala]
----
insertWholeStageCodegen(plan: SparkPlan): SparkPlan
----

`insertWholeStageCodegen` is the main recursive method of `CollapseCodegenStages` that (walks down the `plan` tree and) finds link:spark-sql-CodegenSupport.adoc[physical operators with optional Java code generation] for which <<supportCodegen, Java code can really be generated>> and inserts link:spark-sql-SparkPlan-WholeStageCodegenExec.adoc[WholeStageCodegenExec] operator (with <<insertInputAdapter, InputAdapter>>) for them.

NOTE: `insertWholeStageCodegen` skips physical operators with link:spark-sql-catalyst-QueryPlan.adoc#output[output] with just a single `ObjectType` value (regardless of their support for codegen).

NOTE: `insertWholeStageCodegen` is used recursively by itself and <<insertInputAdapter, insertInputAdapter>>, but more importantly when `CollapseCodegenStages` <<apply, runs>>.

=== [[insertInputAdapter]] Inserting InputAdapter Unary Operator -- `insertInputAdapter` Internal Method

[source, scala]
----
insertInputAdapter(plan: SparkPlan): SparkPlan
----

`insertInputAdapter` inserts an link:spark-sql-SparkPlan-InputAdapter.adoc[InputAdapter] unary operator in a physical plan.

* For link:spark-sql-SparkPlan-SortMergeJoinExec.adoc[SortMergeJoinExec] (with inner and outer joins) <<insertWholeStageCodegen, inserts an InputAdapter operator>> for both children physical operators individually

* For <<supportCodegen, codegen-unsupported>> operators <<insertWholeStageCodegen, inserts an InputAdapter operator>>

* For other operators (except `SortMergeJoinExec` operator above or for which <<supportCodegen, Java code cannot be generated>>) <<insertWholeStageCodegen, inserts an InputAdapter operator>> for every child operator

CAUTION: FIXME Examples for every case + screenshots from web UI

NOTE: `insertInputAdapter` is used in <<insertWholeStageCodegen, insertWholeStageCodegen>> and recursively.

=== [[supportCodegen]][[supportCodegen-SparkPlan]] Physical Operators with Codegen Support -- `supportCodegen` Internal Predicate

[source, scala]
----
supportCodegen(plan: SparkPlan): Boolean
----

`supportCodegen` finds link:spark-sql-SparkPlan.adoc[physical operators] with link:spark-sql-CodegenSupport.adoc[CodegenSupport] and link:spark-sql-CodegenSupport.adoc#supportCodegen[supportCodegen] flag enabled.

[source, scala]
----
import org.apache.spark.sql.SparkSession
val spark: SparkSession = ...
// both where and select support codegen
val query = spark.range(2).where('id === 0).select('id)
scala> query.explain
== Physical Plan ==
*Filter (id#88L = 0)
+- *Range (0, 2, step=1, splits=8)
----

`supportCodegen` is positive when all of the following hold:

* link:spark-sql-Expression.adoc[Catalyst expressions] of the physical operator all <<supportCodegen-Expression, support codegen>>
* Number of nested fields of the link:spark-sql-catalyst-QueryPlan.adoc#schema[schema of the physical operator] is up to link:spark-sql-SQLConf.adoc#spark.sql.codegen.maxFields[spark.sql.codegen.maxFields] internal property (100 by default)
* Number of the nested fields in the schema of the children is up to `spark.sql.codegen.maxFields` (same as above)

Otherwise, `supportCodegen` is negative/disabled.

[source, scala]
----
import org.apache.spark.sql.SparkSession
val spark: SparkSession = ...
// both where and select support codegen
// let's break the requirement of having up to spark.sql.codegen.maxFields
val newSpark = spark.newSession()
import org.apache.spark.sql.internal.SQLConf.WHOLESTAGE_MAX_NUM_FIELDS
newSpark.sessionState.conf.setConf(WHOLESTAGE_MAX_NUM_FIELDS, 2)

scala> println(newSpark.sessionState.conf.wholeStageMaxNumFields)
2

import newSpark.implicits._
val query = Seq((1,2,3)).toDF("id", "c0", "c1").where('id === 0)
scala> query.explain
== Physical Plan ==
Project [_1#452 AS id#456, _2#453 AS c0#457, _3#454 AS c1#458]
+- Filter (_1#452 = 0)
   +- LocalTableScan [_1#452, _2#453, _3#454]
----

=== [[supportCodegen-Expression]] Expressions with Codegen Support -- `supportCodegen` Internal Predicate

[source, scala]
----
supportCodegen(e: Expression): Boolean
----

`supportCodegen` is positive when the link:spark-sql-Expression.adoc[Catalyst expression] `e` is (in the order of verification):

1. link:spark-sql-Expression.adoc#LeafExpression[LeafExpression]
1. non-link:spark-sql-Expression.adoc#CodegenFallback[CodegenFallback] expression

Otherwise, `supportCodegen` is negative.

NOTE: `supportCodegen` (for expressions) is used when <<supportCodegen, supportCodegen>> (for physical plans) finds operators that support codegen.
