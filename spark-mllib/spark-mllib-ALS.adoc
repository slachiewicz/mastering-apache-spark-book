== [[ALS]] ALS

`ALS` is an link:spark-mllib-estimators.adoc[Estimator] that <<fit, generates a ALSModel>>.

`ALS` uses `als-[random-numbers]` for the default identifier.

`ALS` can be fine-tuned using <<ALSParams, parameters>>.

[[ALSParams]]
.ALS's Parameters (aka ALSParams)
[cols="1,1,2",options="header",width="100%"]
|===
| Parameter
| Default Value
| Description

| [[alpha]] `alpha`
| `1.0`
| Alpha parameter in the implicit preference formulation

Must be non-negative, i.e. at least `0`.

| [[checkpointInterval]] `checkpointInterval`
| `10`
| Checkpoint interval, i.e. how many iterations between checkpoints.

Must be at least `1` or exactly `-1` to disable checkpointing

| [[coldStartStrategy]] `coldStartStrategy`
| `nan`
a| Strategy for dealing with unknown or new users/items at prediction time, i.e. what happens for user or item ids the model has not seen in the training data.

Supported values:

* `nan` - predicted value for unknown ids will be NaN
* `drop` - rows in the input DataFrame containing unknown ids are dropped from the output DataFrame (with predictions).

| [[finalStorageLevel]] `finalStorageLevel`
| link:../spark-rdd-StorageLevel.adoc#MEMORY_AND_DISK[MEMORY_AND_DISK]
| link:../spark-rdd-StorageLevel.adoc[StorageLevel] for ALS model factors

| [[implicitPrefs]] `implicitPrefs`
| Disabled (`false`)
| Flag to decide whether to use implicit preference

| [[intermediateStorageLevel]] `intermediateStorageLevel`
| link:../spark-rdd-StorageLevel.adoc#MEMORY_AND_DISK[MEMORY_AND_DISK]
| link:../spark-rdd-StorageLevel.adoc[StorageLevel] for intermediate datasets. Must not be `NONE`.

| [[itemCol]] `itemCol`
| `item`
| Column name for item ids

Must be all integers or link:../spark-sql-DataType.adoc[numerics] within the integer value range

| [[maxIter]] `maxIter`
| `10`
| Maximum number of iterations

Must be non-negative, i.e. at least `0`.

| [[nonnegative]] `nonnegative`
| Disabled (`false`)
| Flag to decide whether to apply nonnegativity constraints for least squares.

| [[numUserBlocks]] `numUserBlocks`
| `10`
| Number of user blocks

Has to be at least `1`.

| [[numItemBlocks]] `numItemBlocks`
| `10`
| Number of item blocks

Has to be at least `1`.

| [[predictionCol]] `predictionCol`
| `prediction`
a| Column name for predictions

* The main purpose of the estimator
* Of type `FloatType`

| [[rank]] `rank`
| `10`
| Rank of the matrix factorization

Has to be at least `1`.

| [[ratingCol]] `ratingCol`
| `rating`
| Column name for ratings

Must be all integers or link:../spark-sql-DataType.adoc[numerics] within the integer value range

| [[regParam]] `regParam`
| `10`
| Regularization parameter

Must be non-negative, i.e. at least `0`.

| [[seed]] `seed`
| Randomly-generated
| Random seed

| [[userCol]] `userCol`
| `user`
| Column name for user ids

Must be all integers or link:../spark-sql-DataType.adoc[numerics] within the integer value range
|===

=== [[fit]] `fit` Method

[source, scala]
----
fit(dataset: Dataset[_]): ALSModel
----

`fit`...FIXME
