== [[YarnScheduler]] YarnScheduler -- TaskScheduler for Client Deploy Mode

`YarnScheduler` is the link:../spark-TaskScheduler.adoc[TaskScheduler] for link:README.adoc[Spark on YARN] in link:spark-submit.adoc#deploy-mode[client deploy mode].

It is a custom link:spark-TaskSchedulerImpl.adoc[TaskSchedulerImpl] with ability to compute racks per hosts, i.e. it comes with a specialized <<getRackForHost, getRackForHost>>.

It also sets `org.apache.hadoop.yarn.util.RackResolver` logger to `WARN` if not set already.

[TIP]
====
Enable `INFO` or `DEBUG` logging levels for `org.apache.spark.scheduler.cluster.YarnScheduler` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.scheduler.cluster.YarnScheduler=DEBUG
```

Refer to link:../spark-logging.adoc[Logging].
====

=== [[getRackForHost]] Tracking Racks per Hosts and Ports (getRackForHost method)

`getRackForHost` attempts to compute the rack for a host.

NOTE: `getRackForHost` overrides the link:spark-TaskSchedulerImpl.adoc#getRackForHost[parent TaskSchedulerImpl's getRackForHost]

It simply uses Hadoop's `org.apache.hadoop.yarn.util.RackResolver` to resolve a hostname to its network location, i.e. a rack.
