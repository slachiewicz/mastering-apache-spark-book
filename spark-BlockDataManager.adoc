== [[BlockDataManager]] BlockDataManager -- Block Storage Management API

`BlockDataManager` is the <<contract, contract>> for managing storage for blocks of data (aka _block storage management API_).

[[contract]]
[source, scala]
----
package org.apache.spark.network

trait BlockDataManager {
  def getBlockData(blockId: BlockId): ManagedBuffer
  def putBlockData(
    blockId: BlockId,
    data: ManagedBuffer,
    level: StorageLevel,
    classTag: ClassTag[_]): Boolean
  def releaseLock(blockId: BlockId, taskAttemptId: Option[Long]): Unit
}
----

NOTE: `BlockDataManager` is a `private[spark]` contract.

.BlockDataManager Contract
[cols="1,2",options="header",width="100%"]
|===
| Method
| Description

| `getBlockData`
a| [[getBlockData]] Fetches a local block data by `blockId`

Used when:

* `NettyBlockRpcServer` is requested to link:spark-NettyBlockRpcServer.adoc#receive-OpenBlocks[handle an OpenBlocks message]

* `ShuffleBlockFetcherIterator` is requested to link:spark-ShuffleBlockFetcherIterator.adoc#fetchLocalBlocks[fetchLocalBlocks]

| `putBlockData`
| [[putBlockData]] Uploads a block data locally by `blockId`. The return value says whether the operation has succeeded (`true`) or failed (`false`).

Used when...FIXME

| `releaseLock`
| [[releaseLock]] Releases the lock for <<getBlockData, getBlockData>> and <<putBlockData, putBlockData>> methods

Used when...FIXME
|===

Blocks are identified by `BlockId` that has a globally unique identifier (`name`) and stored as <<ManagedBuffer, ManagedBuffer>>.

[[BlockId]]
.BlockIds
[width="100%",cols="1,2",options="header"]
|===
| Name
| Description

| [[RDDBlockId]] RDDBlockId
| Described by RDD ID (`rddId`) and a partition index (`splitIndex`)

Created when an `RDD` is requested to link:spark-rdd-RDD.adoc#getOrCompute[get or compute an RDD partition] (identified by `splitIndex`).

| [[ShuffleBlockId]] `ShuffleBlockId`
| Described by `shuffleId`, `mapId` and `reduceId`

| [[ShuffleDataBlockId]] ShuffleDataBlockId
| Described by `shuffleId`, `mapId` and `reduceId`

| [[ShuffleIndexBlockId]] ShuffleIndexBlockId
| Described by `shuffleId`, `mapId` and `reduceId`

| [[BroadcastBlockId]] `BroadcastBlockId`
| Described by `broadcastId` identifier and optional `field`

| [[TaskResultBlockId]] TaskResultBlockId
| Described by `taskId`

| [[StreamBlockId]] StreamBlockId
| Described by `streamId` and `uniqueId`
|===

[[implementations]]
NOTE: link:spark-BlockManager.adoc[BlockManager] is the one and only known implementation of <<contract, BlockDataManager Contract>> in Apache Spark.
