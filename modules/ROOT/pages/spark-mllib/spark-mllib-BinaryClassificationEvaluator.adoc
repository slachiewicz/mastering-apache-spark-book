== [[BinaryClassificationEvaluator]] BinaryClassificationEvaluator -- Evaluator of Binary Classification Models

`BinaryClassificationEvaluator` is an link:spark-mllib-Evaluator.adoc[Evaluator] of cross-validate models from binary classifications (e.g. link:spark-mllib-LogisticRegression.adoc[LogisticRegression], link:spark-mllib-RandomForestClassifier.adoc[RandomForestClassifier], `NaiveBayes`, link:spark-mllib-DecisionTreeClassifier.adoc[DecisionTreeClassifier], `MultilayerPerceptronClassifier`, `GBTClassifier`, `LinearSVC`).

[[isLargerBetter]]
`BinaryClassificationEvaluator` finds the best model by maximizing the model evaluation metric that is the <<metricName, area under the specified curve>> (and so link:spark-mllib-Evaluator.adoc#isLargerBetter[isLargerBetter] is turned on for either <<metricName, metric>>).

```
import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator
val binEval = new BinaryClassificationEvaluator().
  setMetricName("areaUnderROC").
  setRawPredictionCol("rawPrediction").
  setLabelCol("label")

scala> binEval.isLargerBetter
res0: Boolean = true

scala> println(binEval.explainParams)
labelCol: label column name (default: label)
metricName: metric name in evaluation (areaUnderROC|areaUnderPR) (default: areaUnderROC)
rawPredictionCol: raw prediction (a.k.a. confidence) column name (default: rawPrediction)
```

[[parameters]]
.BinaryClassificationEvaluator' Parameters
[cols="1,1,2",options="header",width="100%"]
|===
| Parameter
| Default Value
| Description

| [[metricName]] `metricName`
| `areaUnderROC`
a| Name of the classification metric for evaluation

Can be either `areaUnderROC` (default) or `areaUnderPR`

| [[rawPredictionCol]] `rawPredictionCol`
| `rawPrediction`
| Column name with raw predictions (a.k.a. confidence)

| [[labelCol]] `labelCol`
| `label`
| Name of the column with indexed labels (i.e. ``0``s or ``1``s)
|===

=== [[evaluate]] Evaluating Model Output -- `evaluate` Method

[source, scala]
----
evaluate(dataset: Dataset[_]): Double
----

NOTE: `evaluate` is part of link:spark-mllib-Evaluator.adoc#evaluate[Evaluator Contract].

`evaluate`...FIXME
