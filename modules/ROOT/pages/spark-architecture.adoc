== Spark Architecture

Spark uses a *master/worker architecture*. There is a link:spark-driver.adoc[driver] that talks to a single coordinator called link:spark-master.adoc[master] that manages link:spark-workers.adoc[workers] in which link:spark-Executor.adoc[executors] run.

.Spark architecture
image::images/driver-sparkcontext-clustermanager-workers-executors.png[align="center"]

The driver and the executors run in their own Java processes. You can run them all on the same (_horizontal cluster_) or separate machines (_vertical cluster_) or in a mixed machine configuration.

.Spark architecture in detail
image::images/sparkapp-sparkcontext-master-slaves.png[align="center"]

Physical machines are called *hosts* or *nodes*.
