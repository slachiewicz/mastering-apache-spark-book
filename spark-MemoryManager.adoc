== [[MemoryManager]] MemoryManager -- Memory Management System

`MemoryManager` is an abstract base *memory manager* to manage shared memory for execution and storage.

*Execution memory* is used for computation in shuffles, joins, sorts and aggregations.

*Storage memory* is used for caching and propagating internal data across the nodes in a cluster.

A `MemoryManager` is created when link:spark-SparkEnv.adoc#create[SparkEnv is created] (one per JVM) and can be one of the two possible implementations:

1. link:spark-UnifiedMemoryManager.adoc[UnifiedMemoryManager] -- the default memory manager since Spark 1.6.
2. `StaticMemoryManager` (legacy)

NOTE: `org.apache.spark.memory.MemoryManager` is a `private[spark]` Scala trait in Spark.

=== [[contract]] MemoryManager Contract

Every `MemoryManager` obeys the following contract:

* <<maxOnHeapStorageMemory, maxOnHeapStorageMemory>>
* <<acquireStorageMemory, acquireStorageMemory>>

==== [[acquireStorageMemory]] `acquireStorageMemory`

[source, scala]
----
acquireStorageMemory(blockId: BlockId, numBytes: Long, memoryMode: MemoryMode): Boolean
----

`acquireStorageMemory`

CAUTION: FIXME

`acquireStorageMemory` is used in link:spark-MemoryStore.adoc[MemoryStore] to put bytes.

==== [[maxOffHeapStorageMemory]] `maxOffHeapStorageMemory` Attribute

[source, scala]
----
maxOffHeapStorageMemory: Long
----

CAUTION: FIXME

==== [[maxOnHeapStorageMemory]] `maxOnHeapStorageMemory` Attribute

[source, scala]
----
maxOnHeapStorageMemory: Long
----

`maxOnHeapStorageMemory` is the total amount of memory available for storage, in bytes. It can vary over time.

CAUTION: FIXME Where is this used?

It is used in link:spark-MemoryStore.adoc[MemoryStore] to ??? and link:spark-blockmanager.adoc[BlockManager] to ???

=== [[releaseExecutionMemory]] `releaseExecutionMemory`

=== [[releaseAllExecutionMemoryForTask]] `releaseAllExecutionMemoryForTask`

=== [[tungstenMemoryMode]] `tungstenMemoryMode`

`tungstenMemoryMode` informs others whether Spark works in `OFF_HEAP` or `ON_HEAP` memory mode.

It uses `spark.memory.offHeap.enabled` (default: `false`), `spark.memory.offHeap.size` (default: `0`), and `org.apache.spark.unsafe.Platform.unaligned` before `OFF_HEAP` is assumed.

CAUTION: FIXME Describe `org.apache.spark.unsafe.Platform.unaligned`.
