== [[MemoryManager]] MemoryManager -- Memory Management System

`MemoryManager` is the <<contract, base>> of <<implementations, memory managers>> that manage shared memory for task execution and block storage.

[[contract]]
[source, scala]
----
package org.apache.spark.memory

abstract class MemoryManager(...) {
  // only required methods that have no implementation
  // the others follow
  def acquireExecutionMemory(
    numBytes: Long,
    taskAttemptId: Long,
    memoryMode: MemoryMode): Long
  def acquireStorageMemory(blockId: BlockId, numBytes: Long, memoryMode: MemoryMode): Boolean
  def acquireUnrollMemory(blockId: BlockId, numBytes: Long, memoryMode: MemoryMode): Boolean
  def maxOffHeapStorageMemory: Long
  def maxOnHeapStorageMemory: Long
}
----

NOTE: `MemoryManager` is a `private[spark]` contract.

.(Subset of) MemoryManager Contract
[cols="1,2",options="header",width="100%"]
|===
| Method
| Description

| `acquireExecutionMemory`
| [[acquireExecutionMemory]] Used exclusively when `TaskMemoryManager` is requested to link:spark-TaskMemoryManager.adoc#acquireExecutionMemory[acquireExecutionMemory]

| `acquireStorageMemory`
a| [[acquireStorageMemory]] Used when:

* `UnifiedMemoryManager` is requested to link:spark-UnifiedMemoryManager.adoc#acquireUnrollMemory[acquireUnrollMemory]

* `MemoryStore` is requested to link:spark-MemoryStore.adoc#putBytes[putBytes], link:spark-MemoryStore.adoc#putIteratorAsValues[putIteratorAsValues] and link:spark-MemoryStore.adoc#putIteratorAsBytes[putIteratorAsBytes]

| `acquireUnrollMemory`
| [[acquireUnrollMemory]] Used exclusively when `MemoryStore` is requested to link:spark-MemoryStore.adoc#reserveUnrollMemoryForThisTask[reserveUnrollMemoryForThisTask]

| `maxOffHeapStorageMemory`
a| [[maxOffHeapStorageMemory]] Used when:

* `UnifiedMemoryManager` is requested to link:spark-UnifiedMemoryManager.adoc#acquireStorageMemory[acquireStorageMemory]

* `BlockManager` is link:spark-BlockManager.adoc#maxOffHeapMemory[created]

* `MemoryStore` is requested for the link:spark-MemoryStore.adoc#maxMemory[total amount of memory available for storage (in bytes)]

| `maxOnHeapStorageMemory`
a| [[maxOnHeapStorageMemory]] Used when:

* `BlockManager` is link:spark-BlockManager.adoc#maxOnHeapMemory[created]

* `UnifiedMemoryManager` is requested to link:spark-UnifiedMemoryManager.adoc#acquireStorageMemory[acquireStorageMemory]

* `MemoryStore` is requested for the link:spark-MemoryStore.adoc#maxMemory[total amount of memory available for storage (in bytes)]

* (legacy) `StaticMemoryManager` is link:spark-StaticMemoryManager.adoc#maxOnHeapStorageMemory[created], is requested to link:spark-StaticMemoryManager.adoc#acquireStorageMemory[acquireStorageMemory]
|===

`MemoryManager` is <<creating-instance, created>> along with link:spark-SparkEnv.adoc#create[SparkEnv].

NOTE: `MemoryManager` is a Scala abstract class and cannot be created directly, but only as one of the <<implementations, implementations>>.

*Execution memory* is used for computation in shuffles, joins, sorts and aggregations.

*Storage memory* is used for caching and propagating internal data across the nodes in a cluster.

[[implementations]]
.MemoryManagers
[cols="1,2",options="header",width="100%"]
|===
| MemoryManager
| Description

| link:spark-StaticMemoryManager.adoc[StaticMemoryManager]
| [[StaticMemoryManager]] (legacy)

| link:spark-UnifiedMemoryManager.adoc[UnifiedMemoryManager]
| [[UnifiedMemoryManager]] The default memory manager
|===

[[internal-registries]]
.MemoryManager's Internal Properties (e.g. Registries, Counters and Flags)
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| `onHeapStorageMemoryPool`
| [[onHeapStorageMemoryPool]] FIXME

Used when...FIXME

| `offHeapStorageMemoryPool`
| [[offHeapStorageMemoryPool]] FIXME

Used when...FIXME

| `pageSizeBytes`
| [[pageSizeBytes]] FIXME

Used when...FIXME

| `tungstenMemoryAllocator`
a| [[tungstenMemoryAllocator]] FIXME

Used when...FIXME

NOTE: `tungstenMemoryAllocator` is a Scala `final val` and cannot be changed by custom <<implementations, MemoryManagers>>.
|===

=== [[creating-instance]] Creating MemoryManager Instance

`MemoryManager` takes the following when created:

* [[conf]] link:spark-SparkConf.adoc[SparkConf]
* [[numCores]] Number of CPU cores
* [[onHeapStorageMemory]] `onHeapStorageMemory`
* [[onHeapExecutionMemory]] `onHeapExecutionMemory`

`MemoryManager` initializes the <<internal-registries, internal registries and counters>>.

NOTE: `MemoryManager` is a Scala abstract class and cannot be created directly, but only as one of the <<implementations, implementations>>.

=== [[releaseExecutionMemory]] `releaseExecutionMemory` Method

[source, scala]
----
releaseExecutionMemory(
  numBytes: Long,
  taskAttemptId: Long,
  memoryMode: MemoryMode): Unit
----

`releaseExecutionMemory`...FIXME

NOTE: `releaseExecutionMemory` is used when `TaskMemoryManager` is requested to link:spark-TaskMemoryManager.adoc#releaseExecutionMemory[releaseExecutionMemory] and link:spark-TaskMemoryManager.adoc#cleanUpAllAllocatedMemory[cleanUpAllAllocatedMemory]

=== [[releaseAllExecutionMemoryForTask]] `releaseAllExecutionMemoryForTask` Method

[source, scala]
----
releaseAllExecutionMemoryForTask(taskAttemptId: Long): Long
----

`releaseAllExecutionMemoryForTask`...FIXME

NOTE: `releaseAllExecutionMemoryForTask` is used exclusively when `TaskRunner` is requested to link:spark-executor-TaskRunner.adoc#run[run] (and cleans up after itself).

=== [[tungstenMemoryMode]] `tungstenMemoryMode` Flag

[source, scala]
----
tungstenMemoryMode: MemoryMode
----

`tungstenMemoryMode` returns `OFF_HEAP` only when the following are all met:

* link:spark-MemoryManager-properties.adoc#spark.memory.offHeap.enabled[spark.memory.offHeap.enabled] configuration property is enabled (it is not by default)

* link:spark-MemoryManager-properties.adoc#spark.memory.offHeap.size[spark.memory.offHeap.size] configuration property is greater than `0` (it is `0` by default)

* JVM supports unaligned memory access (aka *unaligned Unsafe*, i.e. `sun.misc.Unsafe` package is available and the underlying system has unaligned-access capability)

Otherwise, `tungstenMemoryMode` returns `ON_HEAP`.

NOTE: Given that link:spark-MemoryManager-properties.adoc#spark.memory.offHeap.enabled[spark.memory.offHeap.enabled] configuration property is disabled (`false`) by default and link:spark-MemoryManager-properties.adoc#spark.memory.offHeap.size[spark.memory.offHeap.size] configuration property is `0` by default, Spark seems to encourage using Tungsten memory allocated on the JVM heap (`ON_HEAP`).

NOTE: `tungstenMemoryMode` is a Scala `final val` and cannot be changed by custom <<implementations, MemoryManagers>>.

[NOTE]
====
`tungstenMemoryMode` is used when:

* `TaskMemoryManager` is link:spark-TaskMemoryManager.adoc#tungstenMemoryMode[created]

* `MemoryManager` is created (and initializes the <<pageSizeBytes, pageSizeBytes>> and <<tungstenMemoryAllocator, tungstenMemoryAllocator>> internal properties)
====

=== [[freePage]] `freePage` Method

[source, java]
----
void freePage(MemoryBlock page)
----

`freePage`...FIXME

NOTE: `freePage` is used when...FIXME
