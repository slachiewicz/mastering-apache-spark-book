== [[BaseRelation]] BaseRelation -- Collection of Tuples with Schema

`BaseRelation` is the <<contract, contract>> in Spark SQL to model a collection of tuples (from a data source) with a <<schema, schema>>.

NOTE: A "data source" and "relation" and "table" are often used as synonyms.

[[sizeInBytes]]
`BaseRelation` can optionally provide information about its estimated size in bytes (as `sizeInBytes`) that defaults to link:spark-sql-SQLConf.adoc#spark.sql.defaultSizeInBytes[spark.sql.defaultSizeInBytes] internal property (i.e. infinite).

[[needConversion]]
`BaseRelation` whether it needs a conversion.

[[unhandledFilters]]
`BaseRelation` computes the list of `Filter` that this data source may not be able to handle.

[[known-implementations]]
.BaseRelation's Known Implementations
[width="100%",cols="1,2",options="header"]
|===
| BaseRelation
| Description

| link:spark-sql-BaseRelation-HadoopFsRelation.adoc[HadoopFsRelation]
|

| link:spark-sql-BaseRelation-JDBCRelation.adoc[JDBCRelation]
|

| `KafkaRelation`
| Structured Streaming's `BaseRelation` for datasets with records from Apache Kafka
|===

NOTE: `BaseRelation` is "created" using ``DataSource``'s link:spark-sql-DataSource.adoc#resolveRelation[resolveRelation].

NOTE: `BaseRelation` is transformed into a link:spark-sql-DataFrame.adoc[DataFrame] using link:spark-sql-SparkSession.adoc#baseRelationToDataFrame[SparkSession.baseRelationToDataFrame].

=== [[contract]] BaseRelation Contract

[source, scala]
----
package org.apache.spark.sql.sources

abstract class BaseRelation {
  // only required methods that have no implementation
  def schema: StructType
  def sqlContext: SQLContext
}
----

.(Subset of) BaseRelation Contract (in alphabetical order)
[cols="1,2",options="header",width="100%"]
|===
| Method
| Description

| [[schema]] `schema`
| link:spark-sql-StructType.adoc[StructType]

| [[sqlContext]] `sqlContext`
| link:spark-sql-SQLContext.adoc[SQLContext]
|===
