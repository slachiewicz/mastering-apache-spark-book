== [[BasicOperators]] BasicOperators Execution Planning Strategy

`BasicOperators` is an link:spark-sql-SparkStrategy.adoc[execution planning strategy] (of link:spark-sql-SparkPlanner.adoc[SparkPlanner]) that in general does simple <<conversions, conversions>> from link:spark-sql-LogicalPlan.adoc[logical operators] to their link:spark-sql-SparkPlan.adoc[physical counterparts].

[[conversions]]
.BasicOperators' Logical to Physical Operator Conversions
[options="header",width="100%",cols="1,1"]
|===
| Logical Operator
| Physical Operator

| [[RunnableCommand]] link:spark-sql-LogicalPlan-RunnableCommand.adoc[RunnableCommand]
| link:spark-sql-SparkPlan-ExecutedCommandExec.adoc[ExecutedCommandExec]

| link:spark-sql-streaming-MemoryPlan.adoc[MemoryPlan]
| link:spark-sql-SparkPlan-LocalTableScanExec.adoc[LocalTableScanExec]

| link:spark-sql-LogicalPlan-DeserializeToObject.adoc[DeserializeToObject]
| `DeserializeToObjectExec`

| `SerializeFromObject` | `SerializeFromObjectExec`
| `MapPartitions` | `MapPartitionsExec`
| `MapElements` | `MapElementsExec`
| `AppendColumns` | `AppendColumnsExec`
| `AppendColumnsWithObject` | `AppendColumnsWithObjectExec`
| `MapGroups` | `MapGroupsExec`
| `CoGroup` | `CoGroupExec`

| `Repartition` (with shuffle enabled)
| link:spark-sql-SparkPlan-ShuffleExchange.adoc[ShuffleExchange]

| `Repartition`
| link:spark-sql-SparkPlan-CoalesceExec.adoc[CoalesceExec]

| `SortPartitions` | `SortExec`
| `Sort` | `SortExec`
| `Project` | `ProjectExec`
| `Filter` | `FilterExec`
| `TypedFilter` | `FilterExec`

| [[Expand]] link:spark-sql-LogicalPlan-Expand.adoc[Expand]
| `ExpandExec`

| [[Window]] link:spark-sql-LogicalPlan-Window.adoc[Window]
| link:spark-sql-SparkPlan-WindowExec.adoc[WindowExec]

| `Sample`
| `SampleExec`

| link:spark-sql-LogicalPlan-LocalRelation.adoc[LocalRelation]
| link:spark-sql-SparkPlan-LocalTableScanExec.adoc[LocalTableScanExec]

| `LocalLimit` | `LocalLimitExec`
| `GlobalLimit` | `GlobalLimitExec`
| `Union` | `UnionExec`

| [[Generate]] link:spark-sql-LogicalPlan-Generate.adoc[Generate]
| [[GenerateExec]] link:spark-sql-SparkPlan-GenerateExec.adoc[GenerateExec]

| [[OneRowRelation]] `OneRowRelation`
| link:spark-sql-SparkPlan-RDDScanExec.adoc[RDDScanExec]

| `Range`
| link:spark-sql-SparkPlan-RangeExec.adoc[RangeExec]

| `RepartitionByExpression`
| link:spark-sql-SparkPlan-ShuffleExchange.adoc[ShuffleExchange]

| `ExternalRDD`
| link:spark-sql-SparkPlan-ExternalRDDScanExec.adoc[ExternalRDDScanExec]

| `LogicalRDD`
| link:spark-sql-SparkPlan-RDDScanExec.adoc[RDDScanExec]

| link:spark-sql-LogicalPlan-BroadcastHint.adoc[BroadcastHint]
| link:spark-sql-SparkStrategy.adoc#PlanLater[PlanLater]
|===

TIP: Confirm the operator mapping in the link:++https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala#L321++[source code of `BasicOperators`].

NOTE: `BasicOperators` expects that `Distinct`, `Intersect`, and `Except` logical operators are not used in a link:spark-sql-LogicalPlan.adoc[logical plan] and throws a `IllegalStateException` if not.
