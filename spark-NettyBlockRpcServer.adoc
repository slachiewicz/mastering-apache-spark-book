== [[NettyBlockRpcServer]] NettyBlockRpcServer

`NettyBlockRpcServer` is a `RpcHandler` (i.e. a handler for `sendRPC()` messages sent by ``TransportClient``s) that handles <<messages, `BlockTransferMessage` messages>> for link:spark-NettyBlockTransferService.adoc[NettyBlockTransferService].

`NettyBlockRpcServer` uses link:spark-OneForOneStreamManager.adoc[OneForOneStreamManager] as the internal `StreamManager`.

[[messages]]
.`NettyBlockRpcServer` Messages
[cols="1,2",options="header",width="100%"]
|===
| Message | Behaviour
| <<OpenBlocks, OpenBlocks>> | Obtaining local blocks and registering them with the internal link:spark-OneForOneStreamManager.adoc[OneForOneStreamManager].
| <<UploadBlock, UploadBlock>> | Deserializes a block and stores it in link:spark-blockdatamanager.adoc[BlockDataManager].
|===

TIP: Enable `TRACE` logging level to see received messages in the logs.

[TIP]
====
Enable `TRACE` logging level for `org.apache.spark.network.netty.NettyBlockRpcServer` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.network.netty.NettyBlockRpcServer=TRACE
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[creating-instance]] Creating NettyBlockRpcServer Instance

[source, scala]
----
class NettyBlockRpcServer(
  appId: String,
  serializer: Serializer,
  blockManager: BlockDataManager)
extends RpcHandler
----

When created, `NettyBlockRpcServer` gets the application id (`appId`) and a `Serializer` and a link:spark-blockdatamanager.adoc[BlockDataManager].

NOTE: `NettyBlockRpcServer` is created when link:spark-NettyBlockTransferService.adoc#init[`NettyBlockTransferService` is initialized].

`NettyBlockRpcServer` merely creates the internal instance of link:spark-OneForOneStreamManager.adoc[OneForOneStreamManager].

NOTE: As a `RpcHandler`, `NettyBlockRpcServer` uses the `OneForOneStreamManager` for `getStreamManager` (which is part of the `RpcHandler` contract).

=== [[OpenBlocks]] Obtaining Local Blocks and Registering with Internal `OneForOneStreamManager` -- `OpenBlocks` Message Handler

When `OpenBlocks` arrives, `NettyBlockRpcServer` link:spark-blockdatamanager.adoc#getBlockData[requests block data (from `BlockDataManager`) for every block id in the message]. The block data is a collection of `ManagedBuffer` for every block id in the incoming message.

NOTE: `BlockDataManager` is given when <<creating-instance, `NettyBlockRpcServer` is created>>.

`NettyBlockRpcServer` then link:spark-OneForOneStreamManager.adoc#registerStream[registers a stream of ``ManagedBuffer``s (for the blocks) with the internal `StreamManager`] under `streamId`.

NOTE: The internal `StreamManager` is link:spark-OneForOneStreamManager.adoc[OneForOneStreamManager] and is created when <<creating-instance, `NettyBlockRpcServer` is created>>.

You should see the following TRACE message in the logs:

```
TRACE NettyBlockRpcServer: Registered streamId [streamId]  with [size] buffers
```

In the end, `NettyBlockRpcServer` responds with a `StreamHandle` (with the `streamId` and the number of blocks). The response is serialized as a `ByteBuffer`.

=== [[UploadBlock]] Deserializing Block and Storing in `BlockDataManager` -- `UploadBlock` Message Handler

When `UploadBlock` arrives, `NettyBlockRpcServer` deserializes the `metadata` of the input message to get the link:spark-rdd-StorageLevel.adoc[StorageLevel] and `ClassTag` of the block being uploaded.

NOTE: `metadata` is serialized before link:spark-NettyBlockTransferService.adoc#uploadBlock[`NettyBlockTransferService` sends a `UploadBlock` message] (using the internal `JavaSerializer`) that is given as `serializer` when <<creating-instance, `NettyBlockRpcServer` is created>>.

`NettyBlockRpcServer` creates a `BlockId` for the block id and requests the link:spark-blockdatamanager.adoc#putBlockData[`BlockDataManager` to store the block].

NOTE: The `BlockDataManager` is passed in when <<creating-instance, `NettyBlockRpcServer` is created>>.

In the end, `NettyBlockRpcServer` responds with a `0`-capacity `ByteBuffer`.

NOTE: `UploadBlock` is sent when link:spark-NettyBlockTransferService.adoc#uploadBlock[`NettyBlockTransferService` uploads a block].
