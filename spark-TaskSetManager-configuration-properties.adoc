== TaskSetManager's Configuration Properties

[[properties]]
.TaskSetManager's Configuration Properties
[cols="1m,3",options="header",width="100%"]
|===
| Name
| Description

| spark.default.parallelism
a| [[spark.default.parallelism]] Number of partitions to use for <<spark-rdd-HashPartitioner.adoc#, HashPartitioner>>.

`spark.default.parallelism` corresponds to link:spark-SchedulerBackend.adoc#defaultParallelism[default parallelism] of a scheduler backend and is as follows:

* The number of threads for link:local/spark-LocalSchedulerBackend.adoc[LocalSchedulerBackend].
* the number of CPU cores in link:spark-mesos.adoc#defaultParallelism[Spark on Mesos] and defaults to `8`.
* Maximum of `totalCoreCount` and `2` in link:spark-CoarseGrainedSchedulerBackend.adoc#defaultParallelism[CoarseGrainedSchedulerBackend].

| spark.driver.maxResultSize
a| [[maxResultSize]][[spark.driver.maxResultSize]][[MAX_RESULT_SIZE]] The maximum size of all results of the tasks in a `TaskSet`

Default: `1g`

Used when:

* `Executor` is <<spark-Executor.adoc#maxResultSize, created>> (and later for a <<spark-Executor-TaskRunner.adoc#, TaskRunner>>)

* `TaskSetManager` is <<spark-TaskSetManager.adoc#maxResultSize, created>> (and later requested to <<spark-TaskSetManager.adoc#canFetchMoreResults, check available memory for task results>>)

| spark.locality.wait
a| [[spark.locality.wait]] For locality-aware delay scheduling for `PROCESS_LOCAL`, `NODE_LOCAL`, and `RACK_LOCAL` link:spark-TaskSchedulerImpl.adoc#TaskLocality[TaskLocalities] when locality-specific setting is not set.

Default: `3s`

| spark.locality.wait.node
a| [[spark.locality.wait.node]] Scheduling delay for `NODE_LOCAL` link:spark-TaskSchedulerImpl.adoc#TaskLocality[TaskLocality]

Default: The value of <<spark.locality.wait, spark.locality.wait>>

| spark.locality.wait.process
a| [[spark.locality.wait.process]] Scheduling delay for `PROCESS_LOCAL` link:spark-TaskSchedulerImpl.adoc#TaskLocality[TaskLocality]

Default: The value of <<spark.locality.wait, spark.locality.wait>>

| spark.locality.wait.rack
a| [[spark.locality.wait.rack]] Scheduling delay for `RACK_LOCAL` link:spark-TaskSchedulerImpl.adoc#TaskLocality[TaskLocality]

Default: The value of <<spark.locality.wait, spark.locality.wait>>

| spark.logging.exceptionPrintInterval
a| [[spark_logging_exceptionPrintInterval]] How frequently to reprint duplicate exceptions in full (in millis).

Default: `10000`

| spark.scheduler.executorTaskBlacklistTime
a| [[spark.scheduler.executorTaskBlacklistTime]] Time interval to pass after which a task can be re-launched on the executor where it has once failed. It is to prevent repeated task failures due to executor failures.

Default: `0L`

| spark.storage.exceptionOnPinLeak
a| [[spark.storage.exceptionOnPinLeak]]

| spark.unsafe.exceptionOnMemoryLeak
a| [[spark.unsafe.exceptionOnMemoryLeak]]

|===
