== TaskSetManager's Configuration Properties

[[properties]]
.TaskSetManager's Configuration Properties
[cols="1,3",options="header",width="100%"]
|===
| Name
| Description

| `spark.driver.maxResultSize`

Default: `1g`
a| [[maxResultSize]][[spark.driver.maxResultSize]] The maximum size of all the task results in a `TaskSet`.

If smaller than `1m` or `1048576` (`1024 * 1024`), it is considered `0`.

Used when:

* `TaskSetManager` is requested to <<spark-TaskSetManager.adoc#canFetchMoreResults, check available memory for a task result>>

* `Utils.getMaxResultSize`

| `spark.scheduler.executorTaskBlacklistTime`

Default: `0L`

| [[spark.scheduler.executorTaskBlacklistTime]] Time interval to pass after which a task can be re-launched on the executor where it has once failed. It is to prevent repeated task failures due to executor failures.

| `spark.logging.exceptionPrintInterval`

Default: `10000`
| [[spark_logging_exceptionPrintInterval]] How frequently to reprint duplicate exceptions in full (in millis).

| `spark.locality.wait`

Default: `3s`
| [[spark.locality.wait]] For locality-aware delay scheduling for `PROCESS_LOCAL`, `NODE_LOCAL`, and `RACK_LOCAL` link:spark-TaskSchedulerImpl.adoc#TaskLocality[TaskLocalities] when locality-specific setting is not set.

| `spark.locality.wait.process`

Default: The value of <<spark.locality.wait, spark.locality.wait>>
| [[spark.locality.wait.process]] Scheduling delay for `PROCESS_LOCAL` link:spark-TaskSchedulerImpl.adoc#TaskLocality[TaskLocality]

| `spark.locality.wait.node`

Default: The value of <<spark.locality.wait, spark.locality.wait>>
| [[spark.locality.wait.node]] Scheduling delay for `NODE_LOCAL` link:spark-TaskSchedulerImpl.adoc#TaskLocality[TaskLocality]

| `spark.locality.wait.rack`

Default: The value of <<spark.locality.wait, spark.locality.wait>>
| [[spark.locality.wait.rack]] Scheduling delay for `RACK_LOCAL` link:spark-TaskSchedulerImpl.adoc#TaskLocality[TaskLocality]

|===
