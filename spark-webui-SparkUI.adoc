== [[SparkUI]] SparkUI -- Web UI of Spark Application

`SparkUI` is the link:spark-webui-WebUI.adoc[web UI] of a Spark application.

`SparkUI` is <<creating-instance, created>> when:

* `SparkContext` is link:spark-sparkcontext-creating-instance-internals.adoc#_ui[created] (for an active Spark application with link:spark-webui.adoc#spark.ui.enabled[spark.ui.enabled] enabled)

* `FsHistoryProvider` is requested to link:spark-history-server-FsHistoryProvider.adoc#getAppUI[getAppUI] (for a complete Spark application)

When started, `SparkUI` binds to <<appUIAddress, appUIAddress>> address that you can control using `SPARK_PUBLIC_DNS` environment variable or link:spark-driver.adoc#spark_driver_host[spark.driver.host] Spark property.

`SparkUI` gets an <<store, AppStatusStore>> that is used when:

* <<initialize, Initializing tabs>>, i.e. link:spark-webui-JobsTab.adoc#creating-instance[JobsTab], link:spark-webui-StagesTab.adoc#creating-instance[StagesTab], link:spark-webui-StorageTab.adoc#creating-instance[StorageTab], link:spark-webui-EnvironmentTab.adoc#creating-instance[EnvironmentTab]

* `AbstractApplicationResource` is requested for link:spark-AbstractApplicationResource.adoc#jobsList[jobsList], link:spark-AbstractApplicationResource.adoc#oneJob[oneJob], link:spark-AbstractApplicationResource.adoc#executorList[executorList], link:spark-AbstractApplicationResource.adoc#allExecutorList[allExecutorList], link:spark-AbstractApplicationResource.adoc#rddList[rddList], link:spark-AbstractApplicationResource.adoc#rddData[rddData], link:spark-AbstractApplicationResource.adoc#environmentInfo[environmentInfo]

* `StagesResource` is requested for link:spark-StagesResource.adoc#stageList[stageList], link:spark-StagesResource.adoc#stageData[stageData], link:spark-StagesResource.adoc#oneAttemptData[oneAttemptData], link:spark-StagesResource.adoc#taskSummary[taskSummary], link:spark-StagesResource.adoc#taskList[taskList]

* `SparkUI` is requested for the current <<getSparkUser, Spark user>>

* Creating Spark SQL's `SQLTab` (when `SQLHistoryServerPlugin` is requested to `setupUI`)

* Spark Streaming's `BatchPage` is created

[[internal-registries]]
.SparkUI's Internal Properties (e.g. Registries, Counters and Flags)
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| `appId`
| [[appId]]
|===

[TIP]
====
Enable `INFO` logging level for `org.apache.spark.ui.SparkUI` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.ui.SparkUI=INFO
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[setAppId]] Assigning Unique Identifier of Spark Application -- `setAppId` Method

[source, scala]
----
setAppId(id: String): Unit
----

`setAppId` sets the internal <<appId, appId>>.

NOTE: `setAppId` is used exclusively when `SparkContext` link:spark-sparkcontext-creating-instance-internals.adoc#spark.app.id[is initialized].

=== [[stop]] Stopping `SparkUI` -- `stop` Method

[source, scala]
----
stop(): Unit
----

`stop` stops the HTTP server and prints the following INFO message to the logs:

```
INFO SparkUI: Stopped Spark web UI at [appUIAddress]
```

NOTE: `appUIAddress` in the above INFO message is the result of <<appUIAddress, appUIAddress>> method.

=== [[appUIAddress]] `appUIAddress` Method

[source, scala]
----
appUIAddress: String
----

`appUIAddress` returns the entire URL of a Spark application's web UI, including `http://` scheme.

Internally, `appUIAddress` uses <<appUIHostPort, appUIHostPort>>.

=== [[getSparkUser]] Accessing Spark User -- `getSparkUser` Method

[source, scala]
----
getSparkUser: String
----

`getSparkUser` returns the name of the user a Spark application runs as.

Internally, `getSparkUser` requests `user.name` System property from link:spark-webui-EnvironmentListener.adoc[EnvironmentListener] Spark listener.

NOTE: `getSparkUser` is used...FIXME

=== [[createLiveUI]] `createLiveUI` Method

[source, scala]
----
createLiveUI(
  sc: SparkContext,
  conf: SparkConf,
  listenerBus: SparkListenerBus,
  jobProgressListener: JobProgressListener,
  securityManager: SecurityManager,
  appName: String,
  startTime: Long): SparkUI
----

`createLiveUI` creates a `SparkUI` for a live running Spark application.

Internally, `createLiveUI` simply forwards the call to <<create, create>>.

NOTE: `createLiveUI` is called when link:spark-sparkcontext-creating-instance-internals.adoc#ui[`SparkContext` is created] (and link:spark-webui.adoc#spark.ui.enabled[spark.ui.enabled] is enabled).

=== [[createHistoryUI]] `createHistoryUI` Method

CAUTION: FIXME

=== [[appUIHostPort]] `appUIHostPort` Method

[source, scala]
----
appUIHostPort: String
----

`appUIHostPort` returns the Spark application's web UI which is the public hostname and port, excluding the scheme.

NOTE: <<appUIAddress, appUIAddress>> uses `appUIHostPort` and adds `http://` scheme.

=== [[getAppName]] `getAppName` Method

[source, scala]
----
getAppName: String
----

`getAppName` returns the name of the Spark application (of a `SparkUI` instance).

NOTE: `getAppName` is used when...FIXME

=== [[create]] Creating SparkUI Instance -- `create` Factory Method

[source, scala]
----
create(
  sc: Option[SparkContext],
  store: AppStatusStore,
  conf: SparkConf,
  securityManager: SecurityManager,
  appName: String,
  basePath: String = "",
  startTime: Long,
  appSparkVersion: String = org.apache.spark.SPARK_VERSION): SparkUI
----

`create` creates a `SparkUI` backed by a link:spark-core-AppStatusStore.adoc[AppStatusStore].

Internally, `create` simply creates a new <<creating-instance, SparkUI>>.

[NOTE]
====
`create` is used when:

* `SparkContext` is link:spark-sparkcontext-creating-instance-internals.adoc#_ui[created] (for a running Spark application)

* `FsHistoryProvider` is requested to link:spark-history-server-FsHistoryProvider.adoc#getAppUI[getAppUI] (for a Spark application that already finished)
====

=== [[creating-instance]] Creating SparkUI Instance

`SparkUI` takes the following when created:

* [[store]] link:spark-core-AppStatusStore.adoc[AppStatusStore]
* [[sc]] link:spark-SparkContext.adoc[SparkContext]
* [[conf]] link:spark-SparkConf.adoc[SparkConf]
* [[securityManager]] `SecurityManager`
* [[appName]] Application name
* [[basePath]] `basePath`
* [[startTime]] Start time
* [[appSparkVersion]] `appSparkVersion`

`SparkUI` initializes the <<internal-registries, internal registries and counters>> and <<initialize, the tabs and handlers>>.

=== [[initialize]] Attaching Tabs and Context Handlers -- `initialize` Method

[source, scala]
----
initialize(): Unit
----

NOTE: `initialize` is part of link:spark-webui-WebUI.adoc#WebUI[WebUI Contract] to initialize web components.

`initialize` creates and <<attachTab, attaches>> the following tabs (with the reference to itself and the <<store, AppStatusStore>>):

. link:spark-webui-JobsTab.adoc[JobsTab]
. link:spark-webui-StagesTab.adoc[StagesTab]
. link:spark-webui-StorageTab.adoc[StorageTab]
. link:spark-webui-EnvironmentTab.adoc[EnvironmentTab]
. link:spark-webui-ExecutorsTab.adoc[ExecutorsTab]

In the end, `initialize` link:spark-webui-WebUI.adoc#attachHandler[attaches the handlers]:

. `/static` to serve static files from `org/apache/spark/ui/static` directory (on CLASSPATH).
. Redirecting `/` to `/jobs/` (so link:spark-webui-jobs.adoc[Jobs tab] is the first tab when you open web UI).
. Serving `/api` context path (with `org.apache.spark.status.api.v1` provider package) using ApiRootResource.
. Redirecting `/jobs/job/kill` to `/jobs/`
. Redirecting `/stages/stage/kill` to `/stages/`
