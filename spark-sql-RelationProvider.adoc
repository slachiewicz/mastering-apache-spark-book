== [[RelationProvider]] RelationProvider -- Data Sources With Schema Inference

`RelationProvider` is a <<contract, contract>> for link:spark-sql-DataSource.adoc#providers[data source providers] that <<createRelation, support schema inference>> (and also can be accessed using SQL's USING clause, i.e. in `CREATE TEMPORARY VIEW` and `DROP DATABASE` DDL operators).

NOTE: *Schema inference* is also called *schema discovery*.

`RelationProvider` is used exclusively when:

* `DataSource` <<resolveRelation, creates a BaseRelation>> (with no user-defined schema or the user-defined schema matches ``RelationProvider``'s)

NOTE: link:spark-sql-BaseRelation.adoc[BaseRelation] models a collection of tuples from an external data source with a schema.

[[implementations]]
.RelationProviders
[width="100%",cols="1,2",options="header"]
|===
| RelationProvider
| Description

| link:spark-sql-JdbcRelationProvider.adoc[JdbcRelationProvider]
|

| link:spark-sql-DataSourceRegister-KafkaSourceProvider.adoc[KafkaSourceProvider]
|
|===

TIP: Use link:spark-sql-SchemaRelationProvider.adoc[SchemaRelationProvider] for relation providers that require a user-defined schema.

=== [[contract]] RelationProvider Contract

[source, scala]
----
package org.apache.spark.sql.sources

trait RelationProvider {
  def createRelation(
    sqlContext: SQLContext,
    parameters: Map[String, String]): BaseRelation
}
----

.RelationProvider Contract
[cols="1,2",options="header",width="100%"]
|===
| Method
| Description

| [[createRelation]] `createRelation`
| Accepts optional parameters (from SQL's `OPTIONS` clause)
|===
