== [[RDD]] RDD

[[T]]
`RDD` is a description of a distributed computation over data of type `T`.

[[id]]
`RDD` is identified by an *RDD ID* that is a unique identifier across all RDDs in a link:spark-SparkContext.adoc[SparkContext].

[source, scala]
----
id: Int
----

[[storageLevel]]
`RDD` has a link:spark-rdd-StorageLevel.adoc[storage level] that...FIXME

[source, scala]
----
storageLevel: StorageLevel
----

The storage level of an RDD is link:spark-rdd-StorageLevel.adoc#NONE[StorageLevel.NONE] by default which is...FIXME

=== [[getOrCompute]] Getting Or Computing RDD Partition -- `getOrCompute` Method

[source, scala]
----
getOrCompute(partition: Partition, context: TaskContext): Iterator[T]
----

`getOrCompute` creates a link:spark-BlockDataManager.adoc#RDDBlockId[RDDBlockId] for the <<id, RDD id>> and the link:spark-rdd-Partition.adoc#index[partition index].

`getOrCompute` requests the `BlockManager` to link:spark-BlockManager.adoc#getOrElseUpdate[getOrElseUpdate] for the block ID, the <<storageLevel, storage level>> and the <<getOrCompute-makeIterator, makeIterator function>> (that...FIXME).

NOTE: `getOrCompute` uses link:spark-SparkEnv.adoc#get[SparkEnv] to access the current link:spark-SparkEnv.adoc#blockManager[BlockManager].

[[getOrCompute-readCachedBlock]]
`getOrCompute` records whether...FIXME (readCachedBlock)

`getOrCompute` branches off per the result of link:spark-BlockManager.adoc#getOrElseUpdate[BlockManager.getOrElseUpdate] and whether the internal `readCachedBlock` flag is on or off. In either case, `getOrCompute` creates an `InterruptibleIterator`.

NOTE: `InterruptibleIterator` simply delegates to a wrapped `Iterator`, but allows for link:spark-taskscheduler-taskcontext.adoc#isInterrupted[task killing functionality].

`getOrCompute`...FIXME

NOTE: `getOrCompute` is used on Spark executors.

NOTE: `getOrCompute` is a `private[spark]` method that is exclusively used when <<iterator, iterating over partition when a RDD is cached>>.

==== [[getOrCompute-makeIterator]] `makeIterator` Function

[source, scala]
----
makeIterator: () => Iterator[T]
----

NOTE: `makeIterator` function is part of link:spark-BlockManager.adoc#getOrElseUpdate[BlockManager.getOrElseUpdate] method that...FIXME
