== [[RDD]] RDD

[[T]]
`RDD` is a description of a distributed computation over data of type `T`.

[[id]]
`RDD` is identified by an *RDD ID* that is a unique identifier across all RDDs in a link:spark-SparkContext.adoc[SparkContext].

[source, scala]
----
id: Int
----

[[storageLevel]]
`RDD` has a link:spark-rdd-StorageLevel.adoc[storage level] that...FIXME

[source, scala]
----
storageLevel: StorageLevel
----

The storage level of an RDD is link:spark-rdd-StorageLevel.adoc#NONE[StorageLevel.NONE] by default which is...FIXME

=== [[getOrCompute]] Getting Or Computing RDD Partition -- `getOrCompute` Method

[source, scala]
----
getOrCompute(partition: Partition, context: TaskContext): Iterator[T]
----

`getOrCompute` creates a link:spark-BlockDataManager.adoc#RDDBlockId[RDDBlockId] for the <<id, RDD id>> and the link:spark-rdd-Partition.adoc#index[partition index].

`getOrCompute` requests the `BlockManager` to link:spark-BlockManager.adoc#getOrElseUpdate[getOrElseUpdate] for the block ID (with the <<storageLevel, storage level>> and the `makeIterator` function).

NOTE: `getOrCompute` uses link:spark-SparkEnv.adoc#get[SparkEnv] to access the current link:spark-SparkEnv.adoc#blockManager[BlockManager].

[[getOrCompute-readCachedBlock]]
`getOrCompute` records whether...FIXME (readCachedBlock)

`getOrCompute` branches off per the result of link:spark-BlockManager.adoc#getOrElseUpdate[BlockManager.getOrElseUpdate] and whether the internal `readCachedBlock` flag is now on or still off. In either case, `getOrCompute` creates an `InterruptibleIterator`.

NOTE: `InterruptibleIterator` simply delegates to a wrapped `Iterator`, but allows for link:spark-taskscheduler-taskcontext.adoc#isInterrupted[task killing functionality].

For a `BlockResult` available and `readCachedBlock` flag on, `getOrCompute`...FIXME

For a `BlockResult` available and `readCachedBlock` flag off, `getOrCompute`...FIXME

NOTE: The `BlockResult` could be found in a local block manager or fetched from a remote block manager. It may also have been stored just now. In either case, the `BlockResult` is available (and link:spark-BlockManager.adoc#getOrElseUpdate[BlockManager.getOrElseUpdate] gives a `Left` value with the `BlockResult`).

For `Right(iter)` (regardless of the value of `readCachedBlock` flag since...FIXME), `getOrCompute`...FIXME

NOTE: link:spark-BlockManager.adoc#getOrElseUpdate[BlockManager.getOrElseUpdate] gives a `Right(iter)` value to indicate an error with a block.

NOTE: `getOrCompute` is used on Spark executors.

NOTE: `getOrCompute` is a `private[spark]` method that is exclusively used when <<iterator, iterating over partition when a RDD is cached>>.
