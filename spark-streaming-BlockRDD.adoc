== [[BlockRDD]] BlockRDD

`BlockRDD` is an link:spark-rdd.adoc[RDD] that is <<creating-instance, created>> when Spark Streaming's `ReceiverInputDStream` is requested to `compute` and `createBlockRDD`.

Spark Streaming calls `BlockRDD.removeBlocks()` while link:spark-streaming/spark-streaming-dstreams.adoc#clearMetadata[clearing metadata].

NOTE: It _appears_ that `BlockRDD` is used in Spark Streaming exclusively.

=== [[compute]] Computing Partition (in TaskContext) -- `compute` Method

[source, scala]
----
compute(split: Partition, context: TaskContext): Iterator[T]
----

NOTE: `compute` is part of link:spark-rdd-RDD.adoc#compute[RDD Contract] to compute a link:spark-rdd-Partition.adoc[partition] (in a link:spark-taskscheduler-TaskContext.adoc[TaskContext]).

`compute`...FIXME

=== [[getPartitions]] `getPartitions` Method

[source, scala]
----
getPartitions: Array[Partition]
----

NOTE: `getPartitions` is part of link:spark-rdd.adoc#getPartitions[RDD Contract] to...FIXME.

`getPartitions`...FIXME

=== [[getPreferredLocations]] `getPreferredLocations` Method

[source, scala]
----
getPreferredLocations(split: Partition): Seq[String]
----

NOTE: `getPreferredLocations` is part of link:spark-rdd.adoc#getPreferredLocations[RDD Contract] to...FIXME.

`getPreferredLocations`...FIXME

=== [[creating-instance]] Creating BlockRDD Instance

`BlockRDD` takes the following when created:

* [[sc]] link:spark-SparkContext.adoc[SparkContext]
* [[blockIds]] Collection of link:spark-BlockDataManager.adoc#BlockId[BlockIds]

`BlockRDD` initializes the <<internal-registries, internal registries and counters>>.
