== [[SQLExecution]] SQLExecution Helper Object

`SQLExecution` defines <<spark.sql.execution.id, spark.sql.execution.id>> key that is used to track multiple jobs that constitute a single SQL query execution. Whenever a SQL query is to be executed, <<withNewExecutionId, withNewExecutionId>> static method is used that sets the key.

NOTE: Jobs without <<spark.sql.execution.id, spark.sql.execution.id>> key are not considered to belong to SQL query executions.

=== [[spark.sql.execution.id]] spark.sql.execution.id EXECUTION_ID_KEY Key

[source, scala]
----
val EXECUTION_ID_KEY = "spark.sql.execution.id"
----

=== [[withNewExecutionId]] Executing Dataset Action (with Zero or More Spark Jobs) with Single Execution Id -- `withNewExecutionId` Method

[source, scala]
----
withExecutionId[T](
  sc: SparkContext,
  executionId: String)(body: => T): T  // <1>

withNewExecutionId[T](
  sparkSession: SparkSession,
  queryExecution: QueryExecution)(body: => T): T  // <2>
----
<1> With explicit `executionId` execution identifier
<2> ``QueryExecution``-variant with an auto-generated execution identifier

`withNewExecutionId` executes `body` query action with a new *execution id* (as the input `executionId` or auto-generated) so that all Spark jobs belong to the `Dataset` action execution.

The execution id is set as `spark.sql.execution.id` link:spark-sparkcontext-local-properties.adoc#setLocalProperty[local property].

`withNewExecutionId` allows for collecting all the Spark jobs (e.g. when running in separate threads) together under a single SQL query execution for reporting purposes, e.g. to link:spark-sql-webui.adoc[reporting them as one single structured query in web UI].

CAUTION: FIXME Where is the proxy-like method used? How important is it?

If there is another execution local property set (as `spark.sql.execution.id`), it is replaced for the course of the current action.

In addition, the `QueryExecution` variant posts link:spark-sql-SQLListener.adoc#SparkListenerSQLExecutionStart[SparkListenerSQLExecutionStart] and link:spark-sql-SQLListener.adoc#SparkListenerSQLExecutionEnd[SparkListenerSQLExecutionEnd] events (to link:spark-LiveListenerBus.adoc[LiveListenerBus] event bus) before and after executing the `body` action, respectively. It is used to inform link:spark-sql-SQLListener.adoc#onOtherEvent[`SQLListener` when a SQL query execution starts and ends].

NOTE: Nested execution ids are not supported in the `QueryExecution` variant.

[NOTE]
====
`withNewExecutionId` is used when:

* `Dataset` is requested to link:spark-sql-Dataset.adoc#withNewExecutionId[Dataset.withNewExecutionId]
* `Dataset` is requested to link:spark-sql-Dataset.adoc#withAction[withAction]

* `DataFrameWriter` is requested to link:spark-sql-DataFrameWriter.adoc#runCommand[run a command]

* Spark Structured Streaming's `StreamExecution` commits a batch to a streaming sink

* Spark Thrift Server's `SparkSQLDriver` runs a command
====
