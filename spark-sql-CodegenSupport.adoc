== [[CodegenSupport]] CodegenSupport -- Physical Operators with Optional Java Code Generation

`CodegenSupport` is an extension of link:spark-sql-SparkPlan.adoc[physical operators] that support *Java code generation* (aka *codegen*).

`CodegenSupport` allows physical operators to <<supportCodegen, disable codegen>>.

TIP: Use link:spark-sql-debugging-execution.adoc#debugCodegen[debugCodegen] or link:spark-sql-QueryExecution.adoc#debug[QueryExecution.debug.codegen] methods to review a ``CodegenSupport``-generated Java source code.

[[variablePrefix]]
`variablePrefix` is...FIXME

[source, scala]
----
val q = spark.range(1)

import org.apache.spark.sql.execution.debug._
scala> q.debugCodegen
Found 1 WholeStageCodegen subtrees.
== Subtree 1 / 1 ==
*Range (0, 1, step=1, splits=8)

Generated code:
...

// The above is equivalent to the following method chain
scala> q.queryExecution.debug.codegen
Found 1 WholeStageCodegen subtrees.
== Subtree 1 / 1 ==
*Range (0, 1, step=1, splits=8)

Generated code:
...
----

=== [[contract]] CodegenSupport Contract

[source, scala]
----
package org.apache.spark.sql.execution

trait CodegenSupport extends SparkPlan {
  // only required methods that have no implementation
  def doProduce(ctx: CodegenContext): String
  def inputRDDs(): Seq[RDD[InternalRow]]
}
----

.(Subset of) CodegenSupport Contract (in alphabetical order)
[cols="1,2",options="header",width="100%"]
|===
| Method
| Description

| [[doProduce]] `doProduce`
| Used exclusively in the final <<produce, produce>> method to generate a Java source code for processing the link:spark-sql-InternalRow.adoc[internal binary rows] from <<inputRDDs, input RDDs>>.

| [[inputRDDs]] `inputRDDs`
a|

NOTE: Up to two input RDDs can be supported.

Used exclusively when `WholeStageCodegenExec` is link:spark-sql-SparkPlan-WholeStageCodegenExec.adoc#doExecute[executed].
|===

=== [[consume]] Generating Java Source Code For...FIXME -- `consume` Final Method

CAUTION: FIXME

=== [[supportCodegen]] `supportCodegen` Flag

[source, scala]
----
supportCodegen: Boolean = true
----

NOTE: `supportCodegen` is used exclusively when `CollapseCodegenStages` link:spark-sql-CollapseCodegenStages.adoc#supportCodegen[checks if a physical operator supports codegen].

[NOTE]
====
`supportCodegen` is disabled for the following physical operators:

* `GenerateExec`
* link:spark-sql-SparkPlan-HashAggregateExec.adoc[HashAggregateExec] with link:spark-sql-Expression-AggregateFunction-ImperativeAggregate.adoc[ImperativeAggregates]
* link:spark-sql-SparkPlan-SortMergeJoinExec.adoc[SortMergeJoinExec] for all link:spark-sql-joins.adoc#join-types[join types] except `INNER` and `CROSS`
====

=== [[produce]] Generating Java Source Code for Physical Operator to Process RDD of Internal Binary Rows -- `produce` Method

[source, scala]
----
produce(ctx: CodegenContext, parent: CodegenSupport): String
----

`produce` generates the Java source code for processing the link:spark-sql-InternalRow.adoc[internal binary rows] from an input RDD for...FIXME

Internally, `produce` link:spark-sql-SparkPlan.adoc#executeQuery[prepares a physical operator for query execution] and then generates a Java source code with the result of <<doProduce, doProduce>>.

While generating the Java source code, `produce` annotates code blocks with `PRODUCE` markers that are link:spark-sql-catalyst-QueryPlan.adoc#simpleString[simple descriptions] of the physical operators in a structured query.

TIP: Enable `spark.sql.codegen.comments` Spark SQL property to have `PRODUCE` markers in the generated Java source code.

[source, scala]
----
// ./bin/spark-shell --conf spark.sql.codegen.comments=true
import org.apache.spark.sql.execution.debug._
val query = Seq((0 to 4).toList).toDF.
  select(explode('value) as "id").
  join(spark.range(1), "id")

scala> query.debugCodegen
Found 2 WholeStageCodegen subtrees.
== Subtree 1 / 2 ==
*Project [id#6]
+- *BroadcastHashJoin [cast(id#6 as bigint)], [id#9L], Inner, BuildRight
   :- Generate explode(value#1), false, false, [id#6]
   :  +- LocalTableScan [value#1]
   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, false]))
      +- *Range (0, 1, step=1, splits=8)
...
/* 043 */   protected void processNext() throws java.io.IOException {
/* 044 */     // PRODUCE: Project [id#6]
/* 045 */     // PRODUCE: BroadcastHashJoin [cast(id#6 as bigint)], [id#9L], Inner, BuildRight
/* 046 */     // PRODUCE: InputAdapter
/* 047 */     while (inputadapter_input.hasNext() && !stopEarly()) {
...
== Subtree 2 / 2 ==
*Range (0, 1, step=1, splits=8)
...
/* 082 */   protected void processNext() throws java.io.IOException {
/* 083 */     // PRODUCE: Range (0, 1, step=1, splits=8)
/* 084 */     // initialize Range

----

NOTE: `produce` is used mainly when `WholeStageCodegenExec` is requested to link:spark-sql-SparkPlan-WholeStageCodegenExec.adoc#doCodeGen[generate the Java source code for a physical plan].
