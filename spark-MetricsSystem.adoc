== [[MetricsSystem]] MetricsSystem

`MetricsSystem` is...FIXME

[[subsystems]]
.Subsystems and Their MetricsSystems (in alphabetical order)
[cols="1,2",options="header",width="100%"]
|===
| Subsystem Name
| When created

| `driver`
| `SparkEnv` link:spark-SparkEnv.adoc#create[is created] for the driver.

| `executor`
| `SparkEnv` link:spark-SparkEnv.adoc#create[is created] for an executor.

| `shuffleService`
| `ExternalShuffleService` link:spark-ExternalShuffleService.adoc#creating-instance[is created].

| `applications`
| Spark Standalone's `Master` link:spark-standalone-master.adoc#creating-instance[is created].

| `master`
| Spark Standalone's `Master` link:spark-standalone-master.adoc#creating-instance[is created].

| `worker`
| Spark Standalone's `Worker` link:spark-standalone-worker.adoc#creating-instance[is created].

| `mesos_cluster`
| Spark on Mesos' `MesosClusterScheduler` is created.
|===

[[internal-properties]]
.MetricsSystem's Internal Properties
[cols="1,1,2",options="header",width="100%"]
|===
| Name
| Initial Value
| Description

| [[metricsConfig]] `metricsConfig`
| link:spark-metrics-MetricsConfig.adoc[MetricsConfig]
| Initialized when `MetricsSystem` <<creating-instance, is created>>.

Used when `MetricsSystem` registers <<registerSinks, sinks>> and <<registerSources, sources>>.

| [[running]] `running`
| Flag whether `MetricsSystem` has already been <<start, started>> or not
| FIXME

| [[metricsServlet]] `metricsServlet`
| (uninitialized)
| FIXME
|===

[[internal-registries]]
.MetricsSystem's Internal Registries and Counters
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[registry]] `registry`
| http://metrics.dropwizard.io/3.1.0/apidocs/com/codahale/metrics/MetricRegistry.html[com.codahale.metrics.MetricRegistry]
| FIXME

| [[sinks]] `sinks`
| link:spark-metrics-Sink.adoc[Metrics sinks] in a Spark application.

Used when `MetricsSystem` <<registerSinks, registers a new metrics sink>> and <<start, starts them eventually>>.

| [[sources]] `sources`
| link:spark-metrics-Source.adoc[Metrics sources] in a Spark application.

Used when `MetricsSystem` <<registerSource, registers a new metrics source>>.
|===

[TIP]
====
Enable `WARN` or `ERROR` logging levels for `org.apache.spark.metrics.MetricsSystem` logger to see what happens in `MetricsSystem`.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.metrics.MetricsSystem=WARN
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[StaticSources]] "Static" Metrics Sources for Spark SQL -- StaticSources

CAUTION: FIXME

=== [[stop]] `stop` Method

CAUTION: FIXME

=== [[removeSource]] `removeSource` Method

CAUTION: FIXME

=== [[report]] `report` Method

CAUTION: FIXME

=== [[createMetricsSystem]] Creating MetricsSystem Instance For Subsystem -- `createMetricsSystem` Factory Method

[source, scala]
----
createMetricsSystem(
  instance: String,
  conf: SparkConf,
  securityMgr: SecurityManager): MetricsSystem
----

`createMetricsSystem` <<creating-instance, creates a `MetricsSystem`>>.

NOTE: `createMetricsSystem` is used when <<subsystems, subsystems>> create their `MetricsSystems`.

=== [[creating-instance]] Creating MetricsSystem Instance

`MetricsSystem` takes the following when created:

* [[instance]] Subsystem name
* [[conf]] link:spark-SparkConf.adoc[SparkConf]
* [[securityMgr]] link:spark-security.adoc[SecurityManager]

`MetricsSystem` initializes the <<internal-registries, internal registries and counters>>.

When created, `MetricsSystem` requests <<metricsConfig, MetricsConfig>> to link:spark-metrics-MetricsConfig.adoc#initialize[initialize].

NOTE: <<createMetricsSystem, createMetricsSystem>> is used to create `MetricsSystems` instead.

=== [[registerSource]] Registering Metrics Source -- `registerSource` Method

[source, scala]
----
registerSource(source: Source): Unit
----

`registerSource` adds `source` to <<sources, sources>> internal registry.

`registerSource` <<buildRegistryName, creates an identifier>> for the metrics source and registers it with <<registry, MetricRegistry>>.

NOTE: `registerSource` uses Metrics' link:++http://metrics.dropwizard.io/3.1.0/apidocs/com/codahale/metrics/MetricRegistry.html#register-java.lang.String-T-++[MetricRegistry.register] to register a metrics source under a given name.

When `registerSource` tries to register a name more than once, you should see the following INFO message in the logs:

```
INFO Metrics already registered
```

[NOTE]
====
`registerSource` is used when:

* `SparkContext` link:spark-SparkContext-creating-instance-internals.adoc#registerSource[registers metrics sources] for:
** link:spark-dagscheduler.adoc#metricsSource[DAGScheduler]
** link:spark-blockmanager-BlockManagerSource.adoc[BlockManager]
** link:spark-ExecutorAllocationManager.adoc#executorAllocationManagerSource[ExecutorAllocationManager] (when link:spark-dynamic-allocation.adoc#isDynamicAllocationEnabled[dynamic allocation is enabled])

* `MetricsSystem` <<start, is started>> (and registers the "static" metrics sources -- `CodegenMetrics` and `HiveCatalogMetrics`) and does <<registerSources, registerSources>>.

* `Executor` link:spark-Executor.adoc#creating-instance[is created] (and registers a link:spark-executor-ExecutorSource.adoc[ExecutorSource])

* `ExternalShuffleService` link:spark-ExternalShuffleService.adoc#start[is started] (and registers `ExternalShuffleServiceSource`)

* Spark Structured Streaming's `StreamExecution` runs batches as data arrives (when metrics are enabled).
* Spark Streaming's `StreamingContext` is started (and registers `StreamingSource`)

* Spark Standalone's `Master` and `Worker` start (and register their `MasterSource` and `WorkerSource`, respectively)
* Spark Standalone's `Master` registers a Spark application (and registers a `ApplicationSource`)
* Spark on Mesos' `MesosClusterScheduler` is started (and registers a `MesosClusterSchedulerSource`)
====

=== [[buildRegistryName]] Building Metrics Source Identifier -- `buildRegistryName` Method

[source, scala]
----
buildRegistryName(source: Source): String
----

NOTE: `buildRegistryName` is used to build the metrics source identifiers for a Spark application's driver and executors, but also for other Spark framework's components (e.g. Spark Standalone's master and workers).

NOTE: `buildRegistryName` uses link:spark-metrics-properties.adoc#spark.metrics.namespace[spark.metrics.namespace] and link:spark-Executor.adoc#spark.executor.id[spark.executor.id] Spark properties to differentiate between a Spark application's driver and executors, and the other Spark framework's components.

(only when <<instance, instance>> is `driver` or `executor`) `buildRegistryName` builds metrics source name that is made up of link:spark-metrics-properties.adoc#spark.metrics.namespace[spark.metrics.namespace], link:spark-Executor.adoc#spark.executor.id[spark.executor.id] and the name of the `source`.

NOTE: `buildRegistryName` uses Metrics' http://metrics.dropwizard.io/3.2.0/apidocs/com/codahale/metrics/MetricRegistry.html[MetricRegistry] to build metrics source identifiers.

CAUTION: FIXME Finish for the other components.

NOTE: `buildRegistryName` is used when `MetricsSystem` <<registerSource, registers>> or <<removeSource, removes>> a metrics source.

=== [[start]] Starting MetricsSystem -- `start` Method

[source, scala]
----
start(): Unit
----

`start` turns <<running, running>> flag on.

NOTE: `start` can only be called once and reports an `IllegalArgumentException` otherwise.

`start` registers the <<StaticSources, "static" metrics sources>> for Spark SQL, i.e. `CodegenMetrics` and `HiveCatalogMetrics`.

`start` then <<registerSources, registerSources>> followed by <<registerSinks, registerSinks>>.

In the end, `start` link:spark-metrics-Sink.adoc#start[starts registered metrics sinks] (from <<sinks, sinks>> registry).

[NOTE]
====
`start` is used when:

* `SparkContext` is link:spark-SparkContext-creating-instance-internals.adoc#MetricsSystem-start[created] (on the driver)

* `SparkEnv` is link:spark-SparkEnv.adoc#create[created] (on executors)

* `ExternalShuffleService` link:spark-ExternalShuffleService.adoc#start[is started]

* Spark Standalone's `Master` and `Worker`, and Spark on Mesos' `MesosClusterScheduler` are requested to start
====

=== [[registerSources]] Registering Metrics Sources for Current Subsystem -- `registerSources` Internal Method

[source, scala]
----
registerSources(): Unit
----

`registerSources` finds <<metricsConfig, metricsConfig>> configuration for the current subsystem (aka `instance`).

NOTE: `instance` is defined when `MetricsSystem` <<creating-instance, is created>>.

`registerSources` finds the configuration of all the link:spark-metrics-Source.adoc[metrics sources] for the subsystem (as described with `source.` prefix).

For every metrics source, `registerSources` finds `class` property, creates an instance, and in the end <<registerSource, registers it>>.

When `registerSources` fails, you should see the following ERROR message in the logs followed by the exception.

```
ERROR Source class [classPath] cannot be instantiated
```

NOTE: `registerSources` is used exclusively when `MetricsSystem` is <<start, started>>.

=== [[getServletHandlers]] `getServletHandlers` Method

[source, scala]
----
getServletHandlers: Array[ServletContextHandler]
----

`getServletHandlers` makes sure that the `MetricsSystem` is <<running, running>> and requests <<metricsServlet, MetricsServlet>> to link:spark-metrics-MetricsServlet.adoc#getHandlers[getHandlers].

NOTE: `getServletHandlers` is used when...FIXME

=== [[registerSinks]] Registering Metrics Sinks -- `registerSinks` Internal Method

[source, scala]
----
registerSinks(): Unit
----

`registerSinks`...FIXME

NOTE: `registerSinks` is used exclusively when `MetricsSystem` is requested to <<start, start>>.
