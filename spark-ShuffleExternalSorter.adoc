== [[ShuffleExternalSorter]] ShuffleExternalSorter -- Cache-Efficient Sorter

`ShuffleExternalSorter` is a specialized cache-efficient sorter that sorts arrays of compressed record pointers and partition ids. By using only 8 bytes of space per record in the sorting array, `ShuffleExternalSorter` can fit more of the array into cache.

`ShuffleExternalSorter` is a link:spark-MemoryConsumer.adoc[MemoryConsumer].

[[internal-properties]]
.ShuffleExternalSorter's Internal Properties
[cols="1,1,2",options="header",width="100%"]
|===
| Name
| Initial Value
| Description

| [[inMemSorter]] `inMemSorter`
| (empty)
| `ShuffleInMemorySorter`

|===

[TIP]
====
Enable `INFO` or `ERROR` logging levels for `org.apache.spark.shuffle.sort.ShuffleExternalSorter` logger to see what happens in `ShuffleExternalSorter`.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.shuffle.sort.ShuffleExternalSorter=INFO
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[getMemoryUsage]] `getMemoryUsage` Method

CAUTION: FIXME

=== [[closeAndGetSpills]] `closeAndGetSpills` Method

CAUTION: FIXME

=== [[insertRecord]] `insertRecord` Method

CAUTION: FIXME

=== [[freeMemory]] `freeMemory` Method

CAUTION: FIXME

=== [[getPeakMemoryUsedBytes]] `getPeakMemoryUsedBytes` Method

CAUTION: FIXME

=== [[writeSortedFile]] `writeSortedFile` Method

CAUTION: FIXME

=== [[cleanupResources]] `cleanupResources` Method

CAUTION: FIXME

=== [[creating-instance]] Creating ShuffleExternalSorter Instance

`ShuffleExternalSorter` takes the following when created:

1. `memoryManager` -- link:spark-taskscheduler-taskmemorymanager.adoc[TaskMemoryManager]
2. `blockManager` -- link:spark-blockmanager.adoc[BlockManager]
3. `taskContext` -- link:spark-taskscheduler-taskcontext.adoc[TaskContext]
4. `initialSize`
5. `numPartitions`
6. link:spark-SparkConf.adoc[SparkConf]
7. `writeMetrics` -- link:spark-taskmetrics-ShuffleWriteMetrics.adoc[ShuffleWriteMetrics]

`ShuffleExternalSorter` initializes itself as a link:spark-MemoryConsumer.adoc[MemoryConsumer] (with `pageSize` as the minimum of `PackedRecordPointer.MAXIMUM_PAGE_SIZE_BYTES` and link:spark-taskscheduler-taskmemorymanager.adoc#pageSizeBytes[pageSizeBytes], and Tungsten memory mode).

[[fileBufferSizeBytes]]
`ShuffleExternalSorter` uses link:spark-ExternalSorter.adoc#spark_shuffle_file_buffer[spark.shuffle.file.buffer] (for `fileBufferSizeBytes`) and `spark.shuffle.spill.numElementsForceSpillThreshold` (for `numElementsForSpillThreshold`) Spark properties.

`ShuffleExternalSorter` creates a <<inMemSorter, ShuffleInMemorySorter>> (with `spark.shuffle.sort.useRadixSort` Spark property enabled by default).

`ShuffleExternalSorter` initializes the <<internal-registries, internal registries and counters>>.

NOTE: `ShuffleExternalSorter` is created when link:spark-UnsafeShuffleWriter.adoc#open[`UnsafeShuffleWriter` is open] (which is when link:spark-UnsafeShuffleWriter.adoc#creating-instance[`UnsafeShuffleWriter` is created]).

=== [[spill]] Freeing Execution Memory by Spilling To Disk -- `spill` Method

[source, java]
----
long spill(long size, MemoryConsumer trigger)
throws IOException
----

NOTE: `spill` is part of link:spark-MemoryConsumer.adoc#contract[MemoryConsumer contract] to sort and spill the current records due to memory pressure.

`spill` <<freeMemory, frees execution memory>>, link:spark-taskscheduler-taskmetrics.adoc#incMemoryBytesSpilled[updates `TaskMetrics`], and in the end returns the spill size.

NOTE: `spill` returns `0` when `ShuffleExternalSorter` has no <<inMemSorter, ShuffleInMemorySorter>> or the `ShuffleInMemorySorter` manages no records.

You should see the following INFO message in the logs:

```
INFO Thread [id] spilling sort data of [memoryUsage] to disk ([size] times so far)
```

`spill` <<writeSortedFile, writes sorted file>> (with `isLastFile` disabled).

`spill` <<freeMemory, frees memory>> and records the spill size.

`spill` resets the internal `ShuffleInMemorySorter` (that in turn frees up the underlying in-memory pointer array).

`spill` link:spark-taskscheduler-taskmetrics.adoc#incMemoryBytesSpilled[adds the spill size to `TaskMetrics`].

`spill` returns the spill size.
