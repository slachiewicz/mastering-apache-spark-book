== [[FileSourceScanExec]] FileSourceScanExec Leaf Physical Operator

`FileSourceScanExec` is a link:spark-sql-SparkPlan-DataSourceScanExec.adoc[DataSourceScanExec] (and so indirectly a link:spark-sql-SparkPlan.adoc#LeafExecNode[leaf physical operator]) that...FIXME

[[inputRDDs]]
`FileSourceScanExec`...FIXME

[[nodeNamePrefix]]
`nodeNamePrefix` is *File*.

[source, scala]
----
FIXME Show the prefix
----

[[internal-registries]]
.FileSourceScanExec's Internal Properties (e.g. Registries, Counters and Flags)
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[inputRDD]] `inputRDD`
| `RDD` of link:spark-sql-InternalRow.adoc[internal binary rows] (i.e. `InternalRow`)

Used when `FileSourceScanExec` is requested for <<inputRDDs, inputRDDs>> and <<doExecute, execution>>.

| [[metadata]] `metadata`
a| Metadata (as a collection of key-value pairs)

NOTE: `metadata` is a part of link:spark-sql-SparkPlan-DataSourceScanExec.adoc#metadata[DataSourceScanExec Contract] to..FIXME.
|===

=== [[doExecute]] Executing FileSourceScanExec -- `doExecute` Method

[source, scala]
----
doExecute(): RDD[InternalRow]
----

NOTE: `doExecute` is a part of link:spark-sql-SparkPlan.adoc#doExecute[SparkPlan Contract] to produce the result of a structured query as an `RDD` of link:spark-sql-InternalRow.adoc[internal binary rows].

`doExecute`...FIXME

=== [[selectedPartitions]] `selectedPartitions` Internal Lazily-Initialized Property

[source, scala]
----
selectedPartitions: Seq[PartitionDirectory]
----

`selectedPartitions`...FIXME

[NOTE]
====
`selectedPartitions` is used when `FileSourceScanExec` calculates:

* <<outputPartitioning, outputPartitioning>> and <<outputOrdering, outputOrdering>> when `spark.sql.sources.bucketing.enabled` Spark property is turned on (which is on by default) and the optional link:spark-sql-BaseRelation-HadoopFsRelation.adoc#bucketSpec[BucketSpec] for <<relation, HadoopFsRelation>> is defined
* <<metadata, metadata>>
* <<inputRDD, inputRDD>>
====
